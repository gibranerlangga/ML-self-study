{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.kaggle.com/crowdflower/twitter-airline-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tweet_airlines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
       "0           0  570306133677760513           neutral   \n",
       "1           1  570301130888122368          positive   \n",
       "2           2  570301083672813571           neutral   \n",
       "3           3  570301031407624196          negative   \n",
       "4           4  570300817074462722          negative   \n",
       "\n",
       "   airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
       "0                        1.0000            NaN                        NaN   \n",
       "1                        0.3486            NaN                     0.0000   \n",
       "2                        0.6837            NaN                        NaN   \n",
       "3                        1.0000     Bad Flight                     0.7033   \n",
       "4                        1.0000     Can't Tell                     1.0000   \n",
       "\n",
       "          airline        name  retweet_count  \\\n",
       "0  Virgin America     cairdin              0   \n",
       "1  Virgin America    jnardino              0   \n",
       "2  Virgin America  yvonnalynn              0   \n",
       "3  Virgin America    jnardino              0   \n",
       "4  Virgin America    jnardino              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2047     1\n",
      "10912    1\n",
      "6806     1\n",
      "661      1\n",
      "2708     1\n",
      "12947    1\n",
      "8849     1\n",
      "10896    1\n",
      "4743     1\n",
      "6790     1\n",
      "645      1\n",
      "2692     1\n",
      "12931    1\n",
      "8833     1\n",
      "10880    1\n",
      "4727     1\n",
      "6774     1\n",
      "629      1\n",
      "2676     1\n",
      "12915    1\n",
      "8817     1\n",
      "10864    1\n",
      "4711     1\n",
      "6758     1\n",
      "613      1\n",
      "2660     1\n",
      "12899    1\n",
      "4759     1\n",
      "8865     1\n",
      "4567     1\n",
      "        ..\n",
      "1274     1\n",
      "11567    1\n",
      "5432     1\n",
      "7481     1\n",
      "7513     1\n",
      "9582     1\n",
      "13676    1\n",
      "3435     1\n",
      "1386     1\n",
      "7529     1\n",
      "5480     1\n",
      "11615    1\n",
      "9566     1\n",
      "13660    1\n",
      "3419     1\n",
      "1370     1\n",
      "5464     1\n",
      "1338     1\n",
      "11599    1\n",
      "9550     1\n",
      "13644    1\n",
      "3403     1\n",
      "1354     1\n",
      "7497     1\n",
      "5448     1\n",
      "11583    1\n",
      "9534     1\n",
      "13628    1\n",
      "3387     1\n",
      "0        1\n",
      "Name: Unnamed: 0, Length: 14640, dtype: int64 \n",
      "\n",
      "\n",
      "570296616688750592    2\n",
      "570273819287531520    2\n",
      "570297548726005761    2\n",
      "570275970046775297    2\n",
      "570306867878072320    2\n",
      "570284862122233856    2\n",
      "570272172679282688    2\n",
      "570307434113310720    2\n",
      "570283851018317824    2\n",
      "570307312675651585    2\n",
      "570267562623152128    2\n",
      "570284054605639683    2\n",
      "570290552169734144    2\n",
      "570290220589027328    2\n",
      "570279118438182913    2\n",
      "570306715599695874    2\n",
      "570283544125288448    2\n",
      "570291157340704769    2\n",
      "570298679250305024    2\n",
      "570307948171423745    2\n",
      "570302358242115584    2\n",
      "569944281512685570    2\n",
      "569622568459636736    2\n",
      "570300177367633921    2\n",
      "570292715444965377    2\n",
      "570276434763128833    2\n",
      "570268326250745856    2\n",
      "570271896887017472    2\n",
      "570302060035497984    2\n",
      "570280641771790336    2\n",
      "                     ..\n",
      "567818156607074304    1\n",
      "568276144107200512    1\n",
      "569472446954389504    1\n",
      "568276647885086720    1\n",
      "569578297945919488    1\n",
      "568100712309256192    1\n",
      "569578441508458496    1\n",
      "568152035767554048    1\n",
      "568188595456118785    1\n",
      "568100626183417856    1\n",
      "569296877902041088    1\n",
      "568417260668379136    1\n",
      "567907070269198337    1\n",
      "569015379021795328    1\n",
      "569683872046194688    1\n",
      "569894969332400128    1\n",
      "567819066708226048    1\n",
      "567988647263252480    1\n",
      "569296784922578944    1\n",
      "568074028990259200    1\n",
      "568663431433187328    1\n",
      "569648584909434880    1\n",
      "568223557806915585    1\n",
      "569633036251340800    1\n",
      "569701285588541441    1\n",
      "569929973156327424    1\n",
      "569929944291127296    1\n",
      "567783687980367872    1\n",
      "569296585697464320    1\n",
      "570074833993670657    1\n",
      "Name: tweet_id, Length: 14485, dtype: int64 \n",
      "\n",
      "\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: airline_sentiment, dtype: int64 \n",
      "\n",
      "\n",
      "1.0000    10445\n",
      "0.6667       71\n",
      "0.6632       35\n",
      "0.6596       30\n",
      "0.6559       30\n",
      "0.6701       29\n",
      "0.6598       28\n",
      "0.6600       26\n",
      "0.6842       26\n",
      "0.6771       24\n",
      "0.6739       22\n",
      "0.6774       22\n",
      "0.6809       22\n",
      "0.6630       22\n",
      "0.6421       22\n",
      "0.6737       22\n",
      "0.6735       21\n",
      "0.6522       20\n",
      "0.6633       19\n",
      "0.6703       19\n",
      "0.6566       19\n",
      "0.6563       18\n",
      "0.6593       17\n",
      "0.6634       17\n",
      "0.6742       17\n",
      "0.6768       17\n",
      "0.6591       16\n",
      "0.6832       16\n",
      "0.6889       16\n",
      "0.6721       15\n",
      "          ...  \n",
      "0.6201        1\n",
      "0.6188        1\n",
      "0.7142        1\n",
      "0.9240        1\n",
      "0.6111        1\n",
      "0.3763        1\n",
      "0.3373        1\n",
      "0.6273        1\n",
      "0.9633        1\n",
      "0.7991        1\n",
      "0.6962        1\n",
      "0.6187        1\n",
      "0.3366        1\n",
      "0.3883        1\n",
      "0.6905        1\n",
      "0.3528        1\n",
      "0.7005        1\n",
      "0.9236        1\n",
      "0.6186        1\n",
      "0.7282        1\n",
      "0.3428        1\n",
      "0.3730        1\n",
      "0.7221        1\n",
      "0.3627        1\n",
      "0.6750        1\n",
      "0.7071        1\n",
      "0.3658        1\n",
      "0.7135        1\n",
      "0.6615        1\n",
      "0.3389        1\n",
      "Name: airline_sentiment_confidence, Length: 1023, dtype: int64 \n",
      "\n",
      "\n",
      "Customer Service Issue         2910\n",
      "Late Flight                    1665\n",
      "Can't Tell                     1190\n",
      "Cancelled Flight                847\n",
      "Lost Luggage                    724\n",
      "Bad Flight                      580\n",
      "Flight Booking Problems         529\n",
      "Flight Attendant Complaints     481\n",
      "longlines                       178\n",
      "Damaged Luggage                  74\n",
      "Name: negativereason, dtype: int64 \n",
      "\n",
      "\n",
      "1.0000    3436\n",
      "0.0000    1344\n",
      "0.6667      62\n",
      "0.6632      33\n",
      "0.6596      29\n",
      "0.6733      25\n",
      "0.6809      25\n",
      "0.3441      24\n",
      "0.6559      24\n",
      "0.6701      23\n",
      "0.6526      22\n",
      "0.6842      21\n",
      "0.6702      21\n",
      "0.6600      21\n",
      "0.6737      20\n",
      "0.6598      20\n",
      "0.6771      19\n",
      "0.6838      18\n",
      "0.6495      18\n",
      "0.6806      18\n",
      "0.3474      18\n",
      "0.6593      18\n",
      "0.6633      18\n",
      "0.6606      17\n",
      "0.6522      17\n",
      "0.6630      17\n",
      "0.3579      17\n",
      "0.3684      17\n",
      "0.6563      17\n",
      "0.6804      17\n",
      "          ... \n",
      "0.6252       1\n",
      "0.6286       1\n",
      "0.6202       1\n",
      "0.6377       1\n",
      "0.5918       1\n",
      "0.3275       1\n",
      "0.6820       1\n",
      "0.7048       1\n",
      "0.3790       1\n",
      "0.6298       1\n",
      "0.3231       1\n",
      "0.3588       1\n",
      "0.3281       1\n",
      "0.3938       1\n",
      "0.6212       1\n",
      "0.7918       1\n",
      "0.3574       1\n",
      "0.3559       1\n",
      "0.3540       1\n",
      "0.6225       1\n",
      "0.6924       1\n",
      "0.7140       1\n",
      "0.3397       1\n",
      "0.6387       1\n",
      "0.7148       1\n",
      "0.6229       1\n",
      "0.3895       1\n",
      "0.3978       1\n",
      "0.6449       1\n",
      "0.3255       1\n",
      "Name: negativereason_confidence, Length: 1410, dtype: int64 \n",
      "\n",
      "\n",
      "United            3822\n",
      "US Airways        2913\n",
      "American          2759\n",
      "Southwest         2420\n",
      "Delta             2222\n",
      "Virgin America     504\n",
      "Name: airline, dtype: int64 \n",
      "\n",
      "\n",
      "JetBlueNews        63\n",
      "kbosspotter        32\n",
      "_mhertz            29\n",
      "otisday            28\n",
      "throthra           27\n",
      "weezerandburnie    23\n",
      "rossj987           23\n",
      "MeeestarCoke       22\n",
      "GREATNESSEOA       22\n",
      "scoobydoo9749      21\n",
      "jasemccarty        20\n",
      "georgetietjen      19\n",
      "ElmiraBudMan       19\n",
      "flemmingerin       19\n",
      "ThatJasonEaton     18\n",
      "Aero0729           18\n",
      "thomashoward88     18\n",
      "chagaga2013        18\n",
      "worldwideweg       17\n",
      "SMHillman          17\n",
      "arthurhasher       16\n",
      "patrick_maness     16\n",
      "heyheyman          16\n",
      "Allisonjones704    15\n",
      "luvthispayne       15\n",
      "geekstiel          14\n",
      "riricesq           14\n",
      "ColtSTaylor        14\n",
      "farfalla818        14\n",
      "davidgoodson71     14\n",
      "                   ..\n",
      "Tyler_Stotts        1\n",
      "fancyfrancois       1\n",
      "lablakeh            1\n",
      "T_Lubinski          1\n",
      "brookem             1\n",
      "amy_lombard         1\n",
      "NicoMancinelli      1\n",
      "jwcriner            1\n",
      "UrbanPranaYoga      1\n",
      "RaquelSnyderDC      1\n",
      "HammerStahl         1\n",
      "heyjdoan            1\n",
      "YoungChipotle       1\n",
      "Ashley_Jeffris      1\n",
      "Will_Watson6        1\n",
      "zinnian0            1\n",
      "klorbe              1\n",
      "JennRanft           1\n",
      "patpohler           1\n",
      "RossWGibson         1\n",
      "mne90               1\n",
      "Matt_Fiorello       1\n",
      "particularmolly     1\n",
      "ByronJ              1\n",
      "N_Brennan           1\n",
      "Mia_Da_Jedi         1\n",
      "SassmasterJosh      1\n",
      "4ensicdds           1\n",
      "StullaDaggera       1\n",
      "sharkb8t            1\n",
      "Name: name, Length: 7701, dtype: int64 \n",
      "\n",
      "\n",
      "0     13873\n",
      "1       640\n",
      "2        66\n",
      "3        22\n",
      "4        17\n",
      "5         5\n",
      "7         3\n",
      "6         3\n",
      "22        2\n",
      "8         1\n",
      "32        1\n",
      "9         1\n",
      "31        1\n",
      "18        1\n",
      "15        1\n",
      "28        1\n",
      "44        1\n",
      "11        1\n",
      "Name: retweet_count, dtype: int64 \n",
      "\n",
      "\n",
      "@united thanks                                                                                                                                           6\n",
      "@JetBlue thanks!                                                                                                                                         5\n",
      "@SouthwestAir sent                                                                                                                                       5\n",
      "@AmericanAir thanks                                                                                                                                      5\n",
      "@united thank you!                                                                                                                                       4\n",
      "@AmericanAir thank you!                                                                                                                                  4\n",
      "@USAirways thank you                                                                                                                                     3\n",
      "@USAirways YOU ARE THE BEST!!! FOLLOW ME PLEASE;)üôèüôèüôè‚úåÔ∏è‚úåÔ∏è‚úåÔ∏èüôèüôèüôè                                                                                            3\n",
      "@SouthwestAir Thank you!                                                                                                                                 3\n",
      "@united Thanks!                                                                                                                                          3\n",
      "@AmericanAir thanks!                                                                                                                                     3\n",
      "@JetBlue thank you!                                                                                                                                      3\n",
      "@united thank you                                                                                                                                        3\n",
      "@SouthwestAir thank you!                                                                                                                                 3\n",
      "@USAirways thanks                                                                                                                                        3\n",
      "@AmericanAir yes yes yes,so glad to be headed home!                                                                                                      2\n",
      "@AmericanAir I don't think you should help him at all based on his behavior. The voucher and cot seem like enough lol üòÉ                                  2\n",
      "@AmericanAir I'd like to apologize to the gate agent for flight AA76, I was not aware that zone 1 was after the nine other precious gems.                2\n",
      "@AmericanAir worst company ever please do not fly with them I repeat please do not fly !! They will not credit you if you're delayed                     2\n",
      "@AmericanAir that's 16+ extra hours of travel time. Missed vacation time and now you guys are messing with my professional life.                         2\n",
      "‚Äú@AmericanAir: @Andrew_Wasila We're sorry you were uncomfortable, Andrew. What can we do for you?‚Äù SMA                                                   2\n",
      "@AmericanAir Would love to DM you, but my Twitter app says you're not following me and I can't.                                                          2\n",
      "@AmericanAir awesome. Thanks!                                                                                                                            2\n",
      "@AmericanAir another day another grievance with this airline. No customer service                                                                        2\n",
      "@AmericanAir did you know that suicide is the second leading cause of death among teens 10-24?                                                           2\n",
      "@AmericanAir FYI...call stilling getting dropped.  After an hour of continuous dialing. Attempted to Cancelled Flight online but not able to. HELP!!!    2\n",
      "@AmericanAir my flight 386 to Dallas from Jacksonville fl has been Cancelled Flightled. No one has notified me. What's going on?                         2\n",
      "@AmericanAir @RobertDwyer AA doesnt charge any fees to change award tickets as long as the origin, destination &amp; award type remains the same         2\n",
      "@AmericanAir I might look into that. My wife travels much more than I do. Could we both use the membership?                                              2\n",
      "@AmericanAir thank you for the confirmation.                                                                                                             2\n",
      "                                                                                                                                                        ..\n",
      "@united Stopped flying @united 1 yr ago bc of aggressive policy on carryon @bdl listening to pssngrs forced to chk@preboard,#notcomingback               1\n",
      "@AmericanAir Delayed: AA3186 - Missed due to delay: AA3186 - New flight now delayed: AA2401                                                              1\n",
      "@AmericanAir seriously, there aren't any reps available to take phone calls? Even for platinum?                                                          1\n",
      "@AmericanAir To announce DURING BOARDING that you chose to limit catering to the point that you WILL run out shows a lack of planning, IMO.              1\n",
      "@united This is the 2nd time I was rebooked (w/delays), and for reasons unreLate Flightd to weather. How do I go about requesting a flight voucher?      1\n",
      "@united thanks for all the help! Totally appreciate it and you made it super easy too                                                                    1\n",
      "@AmericanAir I took the day off from work and drove 9 hours round trip to rescue my daughter and 3 other students from LaGuardia. Thanks!                1\n",
      "@AmericanAir just Cancelled Flightled my 7 am flight tomorrow with out informing me at all today, then booked one in 2 days, and no customer service     1\n",
      "@united tried other flight options as per weblink, non available for next 2 days, frustrating #notgoodenough #poorservice                                1\n",
      "@united hello. I'm overseas &amp; my bag is lost. I can't call customer service but can you help me?                                                     1\n",
      "@USAirways thanks :)                                                                                                                                     1\n",
      "@united Why did you load us in this flying sardine can if you knew the pilots were 2 hours Late Flight?? #incompetent beyond belief                      1\n",
      "@united I normally ask people to put on headphones...but not toddlers. Maybe planes should have a \"kid\" section (near the back) ;)                       1\n",
      "@AmericanAir. All I get is an automated system that hangs up on me. I finally get a message that some will call me back in 2 hours.                      1\n",
      "@AmericanAir I was flying today to MTY Mex at 9:30am but still appear Cancelled Flight, Where can i talk for another flight?                             1\n",
      "@SouthwestAir now I don't get the common courtesy of my phone call answered. Either policy is bad or people should be fired. #dissaponted                1\n",
      "@united Currently on UA862, 20 minutes of the worst turbulence I've ever experienced, and ZERO communication from the flight deck.                       1\n",
      "@united @abigailedge Another glitch??                                                                                                                    1\n",
      "@SouthwestAir, a complete horror show. Flights bumped three times today, before noon, not how to run an airline. #cantblametheweather.                   1\n",
      "@USAirways I want to speak with someone immediately. I am shaking with rage. I offered to hate check my bag and Derrick bussey treated me                1\n",
      "@USAirways You all work hard at making sure things flow smoothly. Keeping positive.                                                                      1\n",
      "@SouthwestAir thank you. I was given this same reply 2 years ago. Can you direct me to an area I can learn more about the improvements?                  1\n",
      "@SouthwestAir PLEASE HELP! I would die to see the Vegas show! It would be amazing to hear their songs for real!                                          1\n",
      "@USAirways but wait! They are booked, along with all other hotels nearby. I was sent anyway, to the hotel managers disbelief.                            1\n",
      "@usairways Ok thank you‚Ä¶I call from Spain to US for seating assistance!                                                                                  1\n",
      "@AmericanAir Group Cancelled Flights close to a thousand #flights Monday http://t.co/v1RADYKEP2                                                          1\n",
      "@United should find a way to distinguish boarding of premier members and credit card holders. Group 2 is too big!                                        1\n",
      "RT @JetBlue: Our fleet's on fleek. http://t.co/NfjAuW16vZ&lt;--....üòï                                                                                     1\n",
      "@united Wife and I have two new destinations and I'm stuck in DC until Monday with no bags                                                               1\n",
      "@SouthwestAir Just got companion pass and trying to add companion flgt but get purchase.error.INVALID_LOYALTY_MEMBER_ACCOUNT_STATUS. Help!               1\n",
      "Name: text, Length: 14427, dtype: int64 \n",
      "\n",
      "\n",
      "[0.0, 0.0]                      164\n",
      "[40.64656067, -73.78334045]       6\n",
      "[32.91792297, -97.00367737]       3\n",
      "[40.64646912, -73.79133606]       3\n",
      "[40.69002464, -73.91638072]       2\n",
      "[39.83426941, -104.69960636]      2\n",
      "[40.68996177, -73.91640136]       2\n",
      "[33.75539049, -116.36196163]      2\n",
      "[37.78618135, -122.45742542]      2\n",
      "[32.82813261, -97.25115941]       2\n",
      "[35.22643463, -80.93879965]       2\n",
      "[18.22245647, -63.00369733]       2\n",
      "[40.69017276, -73.91646118]       2\n",
      "[33.75348859, -116.36209633]      2\n",
      "[40.68994668, -73.91637642]       2\n",
      "[37.99311597, -84.52114659]       2\n",
      "[37.62006843, -122.38822083]      2\n",
      "[39.1766101, -76.6700606]         2\n",
      "[34.0213466, -118.45229268]       2\n",
      "[33.79727578, -117.85043081]      1\n",
      "[41.78959656, -87.74028015]       1\n",
      "[41.95627333, -87.87860345]       1\n",
      "[19.43706642, -99.07927123]       1\n",
      "[43.74167873, -79.3442243]        1\n",
      "[42.19881665, -83.3859395]        1\n",
      "[34.16721627, -118.34537339]      1\n",
      "[33.18882771, -96.64036423]       1\n",
      "[39.24541389, -106.88172648]      1\n",
      "[33.84445776, -116.55139365]      1\n",
      "[-38.0271635, 145.2112317]        1\n",
      "                               ... \n",
      "[39.85871934, -104.67371484]      1\n",
      "[39.99814659, -82.88058383]       1\n",
      "[33.64079948, -84.4358346]        1\n",
      "[29.99135326, -95.52122091]       1\n",
      "[40.64490372, -73.77508276]       1\n",
      "[39.87455718, -75.24082121]       1\n",
      "[42.40805407, -88.62699707]       1\n",
      "[31.93684422, -102.20753682]      1\n",
      "[35.22123472, -80.93287633]       1\n",
      "[40.67851205, -73.43465391]       1\n",
      "[35.21905941, -80.9426995]        1\n",
      "[43.19830037, -70.87348793]       1\n",
      "[32.73130971, -117.20222555]      1\n",
      "[19.43493094, -99.18877967]       1\n",
      "[40.65951726, -74.16980326]       1\n",
      "[13.07787514, -59.6049865]        1\n",
      "[41.30204773, -95.9002533]        1\n",
      "[27.98622757, -82.5414547]        1\n",
      "[43.3230125, -73.64314219]        1\n",
      "[29.65283375, -95.275749]         1\n",
      "[42.3667769, -71.0170733]         1\n",
      "[33.6839241, -117.8607358]        1\n",
      "[35.23908248, -120.64078264]      1\n",
      "[42.5696777, -71.42056878]        1\n",
      "[38.69255098, -121.58854512]      1\n",
      "[32.89873575, -97.04452633]       1\n",
      "[40.64946781, -73.76624703]       1\n",
      "[33.93939612, -118.38973148]      1\n",
      "[34.10909961, -118.32361693]      1\n",
      "[40.69482181, -74.17458032]       1\n",
      "Name: tweet_coord, Length: 832, dtype: int64 \n",
      "\n",
      "\n",
      "2015-02-24 09:54:34 -0800    5\n",
      "2015-02-24 11:43:05 -0800    4\n",
      "2015-02-24 11:32:49 -0800    3\n",
      "2015-02-24 09:14:01 -0800    3\n",
      "2015-02-24 10:01:50 -0800    3\n",
      "2015-02-24 11:38:47 -0800    3\n",
      "2015-02-24 11:38:11 -0800    3\n",
      "2015-02-23 10:58:58 -0800    3\n",
      "2015-02-23 14:18:58 -0800    3\n",
      "2015-02-23 06:57:24 -0800    3\n",
      "2015-02-23 15:25:46 -0800    3\n",
      "2015-02-24 11:40:52 -0800    2\n",
      "2015-02-24 08:22:52 -0800    2\n",
      "2015-02-24 10:55:32 -0800    2\n",
      "2015-02-24 11:36:20 -0800    2\n",
      "2015-02-24 11:04:01 -0800    2\n",
      "2015-02-21 19:28:31 -0800    2\n",
      "2015-02-24 11:01:29 -0800    2\n",
      "2015-02-22 12:04:07 -0800    2\n",
      "2015-02-23 05:32:38 -0800    2\n",
      "2015-02-24 10:06:06 -0800    2\n",
      "2015-02-22 18:00:30 -0800    2\n",
      "2015-02-24 11:41:02 -0800    2\n",
      "2015-02-24 09:18:33 -0800    2\n",
      "2015-02-19 08:43:05 -0800    2\n",
      "2015-02-24 10:02:11 -0800    2\n",
      "2015-02-24 08:47:56 -0800    2\n",
      "2015-02-23 11:50:13 -0800    2\n",
      "2015-02-24 10:05:10 -0800    2\n",
      "2015-02-24 09:34:40 -0800    2\n",
      "                            ..\n",
      "2015-02-22 10:59:25 -0800    1\n",
      "2015-02-22 13:20:20 -0800    1\n",
      "2015-02-21 14:28:55 -0800    1\n",
      "2015-02-22 08:32:36 -0800    1\n",
      "2015-02-20 08:00:33 -0800    1\n",
      "2015-02-19 09:40:33 -0800    1\n",
      "2015-02-23 07:22:59 -0800    1\n",
      "2015-02-23 08:38:28 -0800    1\n",
      "2015-02-21 23:15:02 -0800    1\n",
      "2015-02-22 12:20:30 -0800    1\n",
      "2015-02-20 09:05:13 -0800    1\n",
      "2015-02-21 11:31:44 -0800    1\n",
      "2015-02-23 04:22:39 -0800    1\n",
      "2015-02-19 20:34:41 -0800    1\n",
      "2015-02-20 07:23:23 -0800    1\n",
      "2015-02-22 19:41:06 -0800    1\n",
      "2015-02-19 18:09:56 -0800    1\n",
      "2015-02-18 16:28:09 -0800    1\n",
      "2015-02-21 21:11:21 -0800    1\n",
      "2015-02-19 08:02:51 -0800    1\n",
      "2015-02-23 20:56:39 -0800    1\n",
      "2015-02-18 21:56:17 -0800    1\n",
      "2015-02-21 18:07:21 -0800    1\n",
      "2015-02-17 17:08:00 -0800    1\n",
      "2015-02-18 13:32:17 -0800    1\n",
      "2015-02-24 07:35:09 -0800    1\n",
      "2015-02-18 12:20:34 -0800    1\n",
      "2015-02-19 10:50:05 -0800    1\n",
      "2015-02-21 22:05:59 -0800    1\n",
      "2015-02-18 18:47:08 -0800    1\n",
      "Name: tweet_created, Length: 14247, dtype: int64 \n",
      "\n",
      "\n",
      "Boston, MA                        157\n",
      "New York, NY                      156\n",
      "Washington, DC                    150\n",
      "New York                          127\n",
      "USA                               126\n",
      "Chicago                           104\n",
      "Los Angeles, CA                    96\n",
      "New York City                      96\n",
      "NYC                                95\n",
      "San Francisco, CA                  91\n",
      "San Francisco                      86\n",
      "Chicago, IL                        81\n",
      "Brooklyn, NY                       66\n",
      "Austin, TX                         64\n",
      "Los Angeles                        64\n",
      "Washington, D.C.                   63\n",
      "Boston                             62\n",
      "Dallas, TX                         54\n",
      "Washington DC                      53\n",
      "Nashville, TN                      45\n",
      "Texas                              42\n",
      "NY                                 42\n",
      "San Diego                          38\n",
      "Philadelphia, PA                   38\n",
      "Denver, CO                         37\n",
      "Houston, TX                        35\n",
      "Seattle                            34\n",
      "Global                             34\n",
      "Logan International Airport        32\n",
      "New York, New York                 31\n",
      "                                 ... \n",
      "Kalispell, MT                       1\n",
      "Medway, MA                          1\n",
      "Colyell, Louisiana                  1\n",
      "Beaufort, South Carolina            1\n",
      "√úT: 32.259172,-110.788252           1\n",
      "Marina Del Rey                      1\n",
      "Citizen of the World                1\n",
      "Northwest                           1\n",
      "Highlands Ranch, CO                 1\n",
      "Dallas                              1\n",
      "Windsor& Los Angeles-Cali Life      1\n",
      "Sistine Chapel                      1\n",
      "Titletown, USA                      1\n",
      "‚ú®                                   1\n",
      "Napa, CA                            1\n",
      " California 92705                   1\n",
      "¬¢–ΩŒπ‚Ñì‚ÑìŒπ–∏ Œ±—Ç Œ±–∏ ŒπD ¬¢œÉ–∏¬¢—î—è—Ç            1\n",
      "tejas                               1\n",
      "Chicago Subs                        1\n",
      "Near Los Angeles CA                 1\n",
      "Brandon, Mississippi                1\n",
      "Park Slope                          1\n",
      "Chicago, Illinois                   1\n",
      "Chicago                             1\n",
      "Monterrey, Nuevo Leon               1\n",
      "Santa Rosa, CA                      1\n",
      "Hingham, MA                         1\n",
      "South Carolina/Nashville            1\n",
      "Branchburg, NJ                      1\n",
      "Washington, DC                      1\n",
      "Name: tweet_location, Length: 3081, dtype: int64 \n",
      "\n",
      "\n",
      "Eastern Time (US & Canada)     3744\n",
      "Central Time (US & Canada)     1931\n",
      "Pacific Time (US & Canada)     1208\n",
      "Quito                           738\n",
      "Atlantic Time (Canada)          497\n",
      "Mountain Time (US & Canada)     369\n",
      "Arizona                         229\n",
      "London                          195\n",
      "Alaska                          108\n",
      "Sydney                          107\n",
      "Hawaii                          104\n",
      "Amsterdam                        74\n",
      "America/Chicago                  37\n",
      "Indiana (East)                   26\n",
      "America/New_York                 26\n",
      "Paris                            25\n",
      "Abu Dhabi                        23\n",
      "Brasilia                         23\n",
      "Santiago                         17\n",
      "Greenland                        17\n",
      "Tehran                           17\n",
      "Dublin                           17\n",
      "Athens                           16\n",
      "Casablanca                       15\n",
      "Mid-Atlantic                     15\n",
      "New Delhi                        15\n",
      "America/Los_Angeles              15\n",
      "Buenos Aires                     14\n",
      "Central America                  13\n",
      "Beijing                          11\n",
      "                               ... \n",
      "Guam                              2\n",
      "Islamabad                         2\n",
      "Singapore                         2\n",
      "Lima                              2\n",
      "Hong Kong                         2\n",
      "Nairobi                           2\n",
      "Copenhagen                        2\n",
      "Perth                             2\n",
      "EST                               1\n",
      "Tokyo                             1\n",
      "Irkutsk                           1\n",
      "Saskatchewan                      1\n",
      "Sarajevo                          1\n",
      "Bern                              1\n",
      "Warsaw                            1\n",
      "Istanbul                          1\n",
      "Bucharest                         1\n",
      "Wellington                        1\n",
      "West Central Africa               1\n",
      "Prague                            1\n",
      "Newfoundland                      1\n",
      "Kuala Lumpur                      1\n",
      "Lisbon                            1\n",
      "Monterrey                         1\n",
      "Midway Island                     1\n",
      "Solomon Is.                       1\n",
      "America/Atikokan                  1\n",
      "Canberra                          1\n",
      "Pretoria                          1\n",
      "America/Detroit                   1\n",
      "Name: user_timezone, Length: 85, dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(data[i].value_counts(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categoric = [\"airline\"]\n",
    "drop = [\"tweet_id\", \"Unnamed: 0\", \"name\", \"user_timezone\", \"tweet_location\",\n",
    "        \"negativereason_confidence\", \"negativereason\", \"airline_sentiment_confidence\"]\n",
    "numeric = [\"retweet_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tweet_id', 'airline_sentiment',\n",
       "       'airline_sentiment_confidence', 'negativereason',\n",
       "       'negativereason_confidence', 'airline', 'name', 'retweet_count', 'text',\n",
       "       'tweet_coord', 'tweet_created', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImportData(path, drop):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.drop(drop, axis=1)\n",
    "    print(\"Data shape: \", data.shape)\n",
    "    print(\"Data shape before duplicate: \", data.duplicated().sum())\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Data shape after duplicate: \", data.shape)\n",
    "    print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (14640, 6)\n",
      "Data shape before duplicate:  137\n",
      "Data shape after duplicate:  (14503, 6)\n",
      "  airline_sentiment         airline  retweet_count  \\\n",
      "0           neutral  Virgin America              0   \n",
      "1          positive  Virgin America              0   \n",
      "2           neutral  Virgin America              0   \n",
      "3          negative  Virgin America              0   \n",
      "4          negative  Virgin America              0   \n",
      "\n",
      "                                                text tweet_coord  \\\n",
      "0                @VirginAmerica What @dhepburn said.         NaN   \n",
      "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
      "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
      "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
      "\n",
      "               tweet_created  \n",
      "0  2015-02-24 11:35:52 -0800  \n",
      "1  2015-02-24 11:15:59 -0800  \n",
      "2  2015-02-24 11:15:48 -0800  \n",
      "3  2015-02-24 11:15:36 -0800  \n",
      "4  2015-02-24 11:14:45 -0800  \n"
     ]
    }
   ],
   "source": [
    "data_input = ImportData(\"tweet_airlines.csv\", drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExtractInputOutput(data, output):\n",
    "    data_output = data[output]\n",
    "    data_input = data.drop(output, axis=1)\n",
    "    print(data_input.head())\n",
    "    print(data_output.head())\n",
    "    return data_input, data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          airline  retweet_count  \\\n",
      "0  Virgin America              0   \n",
      "1  Virgin America              0   \n",
      "2  Virgin America              0   \n",
      "3  Virgin America              0   \n",
      "4  Virgin America              0   \n",
      "\n",
      "                                                text tweet_coord  \\\n",
      "0                @VirginAmerica What @dhepburn said.         NaN   \n",
      "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
      "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
      "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
      "\n",
      "               tweet_created  \n",
      "0  2015-02-24 11:35:52 -0800  \n",
      "1  2015-02-24 11:15:59 -0800  \n",
      "2  2015-02-24 11:15:48 -0800  \n",
      "3  2015-02-24 11:15:36 -0800  \n",
      "4  2015-02-24 11:14:45 -0800  \n",
      "0     neutral\n",
      "1    positive\n",
      "2     neutral\n",
      "3    negative\n",
      "4    negative\n",
      "Name: airline_sentiment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x, y = ExtractInputOutput(data_input, 'airline_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10877, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline              0\n",
       "retweet_count        0\n",
       "text                 0\n",
       "tweet_coord      10126\n",
       "tweet_created        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numeric_col.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(x_train.columns,'input_col.pkl')\n",
    "joblib.dump(categoric,'categorical_col.pkl')\n",
    "joblib.dump(numeric,'numeric_col.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CategoricalDummies(data):\n",
    "    data = data.fillna(\"KOSONG\")\n",
    "    dummy_variables = pd.DataFrame([])\n",
    "    label_encoder = pd.Series([])\n",
    "    label_binarizer = pd.Series([])\n",
    "    \n",
    "    for i in list(data):\n",
    "        label_en = LabelEncoder()\n",
    "        label_bin = LabelBinarizer()\n",
    "        \n",
    "        encoded = label_en.fit_transform(data[i])\n",
    "        binary = label_bin.fit_transform(encoded)\n",
    "        \n",
    "        if binary.shape == 1:\n",
    "            dummy = pd.DataFrame(binary, columns = [i], index = data.index)\n",
    "        else:\n",
    "            dummy = pd.DataFrame(binary, columns =[\"{}_{}\".format(a, b) for b in sorted(data[i].unique()) for a in [i]],\n",
    "                                 index = data.index)\n",
    "        \n",
    "        dummy_variables = pd.concat([dummy_variables, dummy], axis=1)\n",
    "        label_encoder[i]=label_en\n",
    "        label_binarizer[i]=label_bin\n",
    "        \n",
    "        return dummy_variables, label_encoder, label_binarizer, dummy_variables.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_dummy, label_encoder, label_binarizer, dummy_columns = CategoricalDummies(x_train[categoric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_American', 'airline_Delta', 'airline_Southwest',\n",
       "       'airline_US Airways', 'airline_United', 'airline_Virgin America'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_binarizer.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump dummy_columns\n",
    "joblib.dump(dummy_columns,'dummy_col.pkl')\n",
    "joblib.dump(label_encoder,'label_encoder.pkl')\n",
    "joblib.dump(label_binarizer,'label_binarizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FitImputNum(data, numeric_column, missing_values, method):\n",
    "    imput = Imputer(missing_values=missing_values, strategy=method)\n",
    "    imput.fit(data[numeric_column])\n",
    "    return data[numeric_column], imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_numeric, imput = FitImputNum(x_train, numeric, 'NaN', 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TransformImput(data, imputer):\n",
    "    data_imput = pd.DataFrame(imputer.transform(data))\n",
    "    data_imput.columns = data.columns\n",
    "    data_imput.index = data.index\n",
    "    print(data_imput.isnull().sum())\n",
    "    print(data_imput.head())\n",
    "    return data_imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retweet_count    0\n",
      "dtype: int64\n",
      "       retweet_count\n",
      "8481             0.0\n",
      "10550            0.0\n",
      "8560             0.0\n",
      "8079             0.0\n",
      "6152             0.0\n"
     ]
    }
   ],
   "source": [
    "x_train_imput_num = TransformImput(x_train_numeric, imput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imputer.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(numeric,'numerical_col.pkl')\n",
    "joblib.dump(imput,'imputer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Time, Coordinate, and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_time = x_train['tweet_created']\n",
    "x_train_coordinate = x_train['tweet_coord']\n",
    "x_train_text = x_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8481     2015-02-18 17:03:04 -0800\n",
       "10550    2015-02-21 09:48:05 -0800\n",
       "8560     2015-02-18 13:46:23 -0800\n",
       "8079     2015-02-20 08:18:47 -0800\n",
       "6152     2015-02-18 14:45:40 -0800\n",
       "Name: tweet_created, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ColumnSplit(data, splitter, columns_name):\n",
    "    data = pd.DataFrame(data.str.split(splitter).tolist(),\n",
    "                       columns = columns_name,\n",
    "                       index = data.index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TimePreprocessing(data):\n",
    "    #ColumnSplit\n",
    "    data = ColumnSplit(data, ' ',['date','time','GMT'])\n",
    "    #again\n",
    "    hour = ColumnSplit(data[\"time\"],':', ['hour','minute','second'])\n",
    "    #again\n",
    "    date = ColumnSplit(data[\"date\"], '-', ['year','month','day'])\n",
    "    \n",
    "    data_return = pd.concat([hour[\"hour\"], date[\"day\"]], axis=1)\n",
    "    \n",
    "    return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_time_clean = TimePreprocessing(x_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12380</th>\n",
       "      <td>05</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>02</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11646</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hour day\n",
       "5218    13  21\n",
       "12380   05  24\n",
       "1346    02  23\n",
       "11646   17  17\n",
       "3582    19  18"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_time_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_time_clean['hour'] = x_train_time_clean['hour'].apply(lambda x: int(x))\n",
    "x_train_time_clean['day'] = x_train_time_clean['day'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CoordPreprocessing(data):\n",
    "    coord = data.fillna(value = \"0.0, 0.0\")\n",
    "    get_coord = coord.str[1:-1]\n",
    "    split_coord = ColumnSplit(get_coord, ', ', [\"latitude\",\"longitude\"])\n",
    "    for i in list(split_coord):\n",
    "        split_coord[i] = pd.to_numeric(split_coord[i])\n",
    "    \n",
    "    return split_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_coordinate_clean = CoordPreprocessing(x_train_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8079</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude\n",
       "8481        0.0        0.0\n",
       "10550       0.0        0.0\n",
       "8560        0.0        0.0\n",
       "8079        0.0        0.0\n",
       "6152        0.0        0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_coordinate_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10877.000000</td>\n",
       "      <td>10877.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.085899</td>\n",
       "      <td>-4.896479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.697205</td>\n",
       "      <td>21.420590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-38.027164</td>\n",
       "      <td>-157.918466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53.367294</td>\n",
       "      <td>151.208213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude     longitude\n",
       "count  10877.000000  10877.000000\n",
       "mean       2.085899     -4.896479\n",
       "std        8.697205     21.420590\n",
       "min      -38.027164   -157.918466\n",
       "25%        0.000000      0.000000\n",
       "50%        0.000000      0.000000\n",
       "75%        0.000000      0.000000\n",
       "max       53.367294    151.208213"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_coordinate_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TextPreprocessing(text, stemmer, lemmatizer):\n",
    "    clear_text = pd.Series([])\n",
    "    for i in text.index:\n",
    "        string = text[i]\n",
    "        #Preprocess using Regex\n",
    "        string = str(string)\n",
    "        string = re.sub('[^A-Za-z0-9]+', ' ', string) #removing symbols\n",
    "        string = re.sub(' +',' ',string.strip()) #removing multiple whitespaces\n",
    "        string = string.lower()\n",
    "        \n",
    "        #Stemming\n",
    "        string = str(string)\n",
    "        string = string.split(\" \")\n",
    "        string = [stemmer.stem(word) for word in string]\n",
    "        string = \" \".join(string)\n",
    "        string = str(string)\n",
    "        \n",
    "        #Lemmatizing\n",
    "        string = string.split(\" \")\n",
    "        string = [lemmatizer.lemmatize(word) for word in string]\n",
    "        string = \" \".join(string)\n",
    "        string = str(string)\n",
    "        \n",
    "        #save it to clear_text[i]\n",
    "        clear_text[i] = string\n",
    "\n",
    "    return clear_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gibranerlangga/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_text_clean = TextPreprocessing(x_train_text, stemmer, lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8481                  jetblu i would go anywher jetblu goe\n",
       "10550    usairway i m tri to cancel flight my flight wi...\n",
       "8560       jetblu is the trueblu site broken at the moment\n",
       "8079     jetblu that s what we ve been told howev how w...\n",
       "6152     southwestair it took age for one snapchat stor...\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 500, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FitVectorizer(text, vectorizer):\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TransformText(text, vectorizer):\n",
    "    #transform using vectorizer\n",
    "    vectorized_text = vectorizer.transform(text)\n",
    "    #make feature_word\n",
    "    feature_word = pd.DataFrame(vectorized_text.toarray(), columns = vectorizer.get_feature_names(),\n",
    "    index = text.index)\n",
    "    return feature_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = FitVectorizer(x_train_text_clean, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_text_feature = TransformText(x_train_text_clean, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>americanair</th>\n",
       "      <th>bag</th>\n",
       "      <th>cancel</th>\n",
       "      <th>custom</th>\n",
       "      <th>delay</th>\n",
       "      <th>fli</th>\n",
       "      <th>flight</th>\n",
       "      <th>help</th>\n",
       "      <th>hour</th>\n",
       "      <th>http</th>\n",
       "      <th>...</th>\n",
       "      <th>need</th>\n",
       "      <th>plane</th>\n",
       "      <th>servic</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>thank</th>\n",
       "      <th>time</th>\n",
       "      <th>unit</th>\n",
       "      <th>usairway</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8079</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       americanair  bag    cancel  custom  delay  fli    flight  help  \\\n",
       "8481           0.0  0.0  0.000000     0.0    0.0  0.0  0.000000   0.0   \n",
       "10550          0.0  0.0  0.498611     0.0    0.0  0.0  0.627554   0.0   \n",
       "8560           0.0  0.0  0.000000     0.0    0.0  0.0  0.000000   0.0   \n",
       "8079           0.0  0.0  0.000000     0.0    0.0  0.0  0.000000   0.0   \n",
       "6152           0.0  0.0  0.000000     0.0    0.0  0.0  0.000000   0.0   \n",
       "\n",
       "           hour  http  ...   need  plane  servic  southwestair  thank  time  \\\n",
       "8481   0.000000   0.0  ...    0.0    0.0     0.0           0.0    0.0   0.0   \n",
       "10550  0.485454   0.0  ...    0.0    0.0     0.0           0.0    0.0   0.0   \n",
       "8560   0.000000   0.0  ...    0.0    0.0     0.0           0.0    0.0   0.0   \n",
       "8079   0.000000   0.0  ...    0.0    0.0     0.0           0.0    0.0   0.0   \n",
       "6152   0.000000   0.0  ...    0.0    0.0     0.0           1.0    0.0   0.0   \n",
       "\n",
       "       unit  usairway   wa  wait  \n",
       "8481    0.0  0.000000  0.0   0.0  \n",
       "10550   0.0  0.349138  0.0   0.0  \n",
       "8560    0.0  0.000000  0.0   0.0  \n",
       "8079    0.0  0.000000  0.0   0.0  \n",
       "6152    0.0  0.000000  0.0   0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Text, Coordinate, Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitStandardize(data):\n",
    "    standard = StandardScaler()\n",
    "    standard.fit(data)\n",
    "    return standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformStandardize(data, standard):\n",
    "    data_standard = pd.DataFrame(standard.transform(data))\n",
    "    data_standard.columns = data.columns\n",
    "    data_standard.index = data.index\n",
    "    print(data_standard.head())\n",
    "    return data_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_concat = pd.concat([x_train_imput_num, x_train_coordinate_clean, x_train_text_feature, x_train_time_clean], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>americanair</th>\n",
       "      <th>bag</th>\n",
       "      <th>cancel</th>\n",
       "      <th>custom</th>\n",
       "      <th>delay</th>\n",
       "      <th>fli</th>\n",
       "      <th>flight</th>\n",
       "      <th>...</th>\n",
       "      <th>servic</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>thank</th>\n",
       "      <th>time</th>\n",
       "      <th>unit</th>\n",
       "      <th>usairway</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8079</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       retweet_count  latitude  longitude  americanair  bag    cancel  custom  \\\n",
       "8481             0.0       0.0        0.0          0.0  0.0  0.000000     0.0   \n",
       "10550            0.0       0.0        0.0          0.0  0.0  0.498611     0.0   \n",
       "8560             0.0       0.0        0.0          0.0  0.0  0.000000     0.0   \n",
       "8079             0.0       0.0        0.0          0.0  0.0  0.000000     0.0   \n",
       "6152             0.0       0.0        0.0          0.0  0.0  0.000000     0.0   \n",
       "\n",
       "       delay  fli    flight ...   servic  southwestair  thank  time  unit  \\\n",
       "8481     0.0  0.0  0.000000 ...      0.0           0.0    0.0   0.0   0.0   \n",
       "10550    0.0  0.0  0.627554 ...      0.0           0.0    0.0   0.0   0.0   \n",
       "8560     0.0  0.0  0.000000 ...      0.0           0.0    0.0   0.0   0.0   \n",
       "8079     0.0  0.0  0.000000 ...      0.0           0.0    0.0   0.0   0.0   \n",
       "6152     0.0  0.0  0.000000 ...      0.0           1.0    0.0   0.0   0.0   \n",
       "\n",
       "       usairway   wa  wait  hour  day  \n",
       "8481   0.000000  0.0   0.0    17   18  \n",
       "10550  0.349138  0.0   0.0     9   21  \n",
       "8560   0.000000  0.0   0.0    13   18  \n",
       "8079   0.000000  0.0   0.0     8   20  \n",
       "6152   0.000000  0.0   0.0    14   18  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard = fitStandardize(x_train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       retweet_count  latitude  longitude  americanair       bag    cancel  \\\n",
      "8481       -0.104882 -0.239847   0.228598    -0.454683 -0.219656 -0.264587   \n",
      "10550      -0.104882 -0.239847   0.228598    -0.454683 -0.219656  3.160662   \n",
      "8560       -0.104882 -0.239847   0.228598    -0.454683 -0.219656 -0.264587   \n",
      "8079       -0.104882 -0.239847   0.228598    -0.454683 -0.219656 -0.264587   \n",
      "6152       -0.104882 -0.239847   0.228598    -0.454683 -0.219656 -0.264587   \n",
      "\n",
      "         custom     delay       fli    flight    ...       servic  \\\n",
      "8481  -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146   \n",
      "10550 -0.254036 -0.259219 -0.219469  2.005284    ...    -0.262146   \n",
      "8560  -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146   \n",
      "8079  -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146   \n",
      "6152  -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146   \n",
      "\n",
      "       southwestair     thank      time      unit  usairway        wa  \\\n",
      "8481      -0.416764 -0.343903 -0.252026 -0.542242 -0.466184 -0.310905   \n",
      "10550     -0.416764 -0.343903 -0.252026 -0.542242  0.836675 -0.310905   \n",
      "8560      -0.416764 -0.343903 -0.252026 -0.542242 -0.466184 -0.310905   \n",
      "8079      -0.416764 -0.343903 -0.252026 -0.542242 -0.466184 -0.310905   \n",
      "6152       3.337552 -0.343903 -0.252026 -0.542242 -0.466184 -0.310905   \n",
      "\n",
      "           wait      hour       day  \n",
      "8481  -0.221934  0.875659 -1.346131  \n",
      "10550 -0.221934 -0.626398  0.036960  \n",
      "8560  -0.221934  0.124631 -1.346131  \n",
      "8079  -0.221934 -0.814155 -0.424070  \n",
      "6152  -0.221934  0.312388 -1.346131  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_standardize = transformStandardize(x_train_concat, standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizer.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(standard, 'normalizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8079</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "8481                  0              1                  0                   0   \n",
       "10550                 0              0                  0                   1   \n",
       "8560                  0              1                  0                   0   \n",
       "8079                  0              1                  0                   0   \n",
       "6152                  0              0                  1                   0   \n",
       "\n",
       "       airline_United  airline_Virgin America  \n",
       "8481                0                       0  \n",
       "10550               0                       0  \n",
       "8560                0                       0  \n",
       "8079                0                       0  \n",
       "6152                0                       0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_standardize = pd.concat([data_train_dummy, x_train_standardize], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_standardize.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>americanair</th>\n",
       "      <th>...</th>\n",
       "      <th>servic</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>thank</th>\n",
       "      <th>time</th>\n",
       "      <th>unit</th>\n",
       "      <th>usairway</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>-0.239847</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>-1.346131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>-0.239847</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>0.836675</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-0.626398</td>\n",
       "      <td>0.036960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>-0.239847</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>0.124631</td>\n",
       "      <td>-1.346131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8079</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>-0.239847</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-0.814155</td>\n",
       "      <td>-0.424070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>-0.239847</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>3.337552</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>0.312388</td>\n",
       "      <td>-1.346131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "8481                  0              1                  0                   0   \n",
       "10550                 0              0                  0                   1   \n",
       "8560                  0              1                  0                   0   \n",
       "8079                  0              1                  0                   0   \n",
       "6152                  0              0                  1                   0   \n",
       "\n",
       "       airline_United  airline_Virgin America  retweet_count  latitude  \\\n",
       "8481                0                       0      -0.104882 -0.239847   \n",
       "10550               0                       0      -0.104882 -0.239847   \n",
       "8560                0                       0      -0.104882 -0.239847   \n",
       "8079                0                       0      -0.104882 -0.239847   \n",
       "6152                0                       0      -0.104882 -0.239847   \n",
       "\n",
       "       longitude  americanair    ...       servic  southwestair     thank  \\\n",
       "8481    0.228598    -0.454683    ...    -0.262146     -0.416764 -0.343903   \n",
       "10550   0.228598    -0.454683    ...    -0.262146     -0.416764 -0.343903   \n",
       "8560    0.228598    -0.454683    ...    -0.262146     -0.416764 -0.343903   \n",
       "8079    0.228598    -0.454683    ...    -0.262146     -0.416764 -0.343903   \n",
       "6152    0.228598    -0.454683    ...    -0.262146      3.337552 -0.343903   \n",
       "\n",
       "           time      unit  usairway        wa      wait      hour       day  \n",
       "8481  -0.252026 -0.542242 -0.466184 -0.310905 -0.221934  0.875659 -1.346131  \n",
       "10550 -0.252026 -0.542242  0.836675 -0.310905 -0.221934 -0.626398  0.036960  \n",
       "8560  -0.252026 -0.542242 -0.466184 -0.310905 -0.221934  0.124631 -1.346131  \n",
       "8079  -0.252026 -0.542242 -0.466184 -0.310905 -0.221934 -0.814155 -0.424070  \n",
       "6152  -0.252026 -0.542242 -0.466184 -0.310905 -0.221934  0.312388 -1.346131  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_standardize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.627930\n",
       "neutral     0.210352\n",
       "positive    0.161717\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DT_fit(x_train, y_train, scoring = 'accuracy'):\n",
    "    decTree = DecisionTreeClassifier(random_state = 123)\n",
    "    \n",
    "    hyperparam = {'min_samples_leaf': [3,5,7,9,13,17,21,27,33,41,50,60,80,100],\n",
    "                 'max_features': ['sqrt','log2', 0.25, 0.5, 0.75]}\n",
    "    \n",
    "    random_decTree = RandomizedSearchCV(decTree, param_distributions = hyperparam, cv = 5, \n",
    "                                       n_iter = 15, scoring = scoring, n_jobs=-1, random_state=123)\n",
    "    \n",
    "    random_decTree.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best Accuracy: \", random_decTree.best_score_)\n",
    "    print(\"Best Params: \", random_decTree.best_params_)\n",
    "    \n",
    "    return random_decTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy:  0.689252551255\n",
      "Best Params:  {'min_samples_leaf': 33, 'max_features': 0.75}\n"
     ]
    }
   ],
   "source": [
    "best_decTree = DT_fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=0.75, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=33, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decTree = DecisionTreeClassifier(min_samples_leaf=best_decTree.best_params_.get('min_samples_leaf'),\n",
    "                                max_features = best_decTree.best_params_.get('max_features'),\n",
    "                                random_state = 123)\n",
    "decTree.fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging_fit(x_train, y_train, scoring='accuracy'):\n",
    "    decTree = DecisionTreeClassifier(random_state = 123)\n",
    "    \n",
    "    bagging = BaggingClassifier(base_estimator=decTree, random_state=123)\n",
    "    \n",
    "    hyperparam = {'base_estimator__min_samples_leaf': [3,5,7,9,13,17,21,27,33,41,50,60,80,100],\n",
    "                 'n_estimators': [100,200,300,500,1000]}\n",
    "    \n",
    "    random_bagging = RandomizedSearchCV(bagging, param_distributions=hyperparam, cv = 5, n_iter = 10, scoring = scoring, n_jobs=-1, random_state=123)\n",
    "    \n",
    "    random_bagging.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best Accuracy:\", random_bagging.best_score_)\n",
    "    print(\"Best Params:\", random_bagging.best_params_)\n",
    "    return random_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.69191872759\n",
      "Best Params: {'n_estimators': 500, 'base_estimator__min_samples_leaf': 13}\n"
     ]
    }
   ],
   "source": [
    "best_bagging = bagging_fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=13, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "         random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decTree_bagging = DecisionTreeClassifier(min_samples_leaf=best_bagging.best_params_.get('base_estimator__min_samples_leaf'),\n",
    "                                        random_state = 123)\n",
    "bagging = BaggingClassifier(base_estimator = decTree_bagging, n_estimators=best_bagging.best_params_.get('n_estimators'),\n",
    "                           n_jobs=-1, random_state = 123)\n",
    "bagging.fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomforest_fit(x_train, y_train, scoring='accuracy'):\n",
    "    randomforest = RandomForestClassifier(random_state = 123)\n",
    "    \n",
    "    hyperparam = {'min_samples_leaf': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n",
    "                 'max_features': ['sqrt','log2', 0.25, 0.5, 0.75],\n",
    "                 'n_estimators': [100, 200,300, 500, 1000]}\n",
    "    \n",
    "    random_randomforest = RandomizedSearchCV(randomforest, param_distributions=hyperparam, cv = 5, n_iter = 10, scoring = scoring, \n",
    "                                            n_jobs = -1, random_state = 123)\n",
    "    \n",
    "    random_randomforest.fit(x_train, y_train)\n",
    "    \n",
    "    print('Best Accuracy: ', random_randomforest.best_score_)\n",
    "    print('Best Params: ', random_randomforest.best_params_)\n",
    "    \n",
    "    return random_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy:  0.695688149306\n",
      "Best Params:  {'n_estimators': 300, 'min_samples_leaf': 9, 'max_features': 0.25}\n"
     ]
    }
   ],
   "source": [
    "best_randomforest = randomforest_fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.25, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=9, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest = RandomForestClassifier(random_state=123, n_jobs=-1, min_samples_leaf = best_randomforest.best_params_.get('min_samples_leaf'),\n",
    "                                     max_features = best_randomforest.best_params_.get('max_features'),\n",
    "                                     n_estimators = best_randomforest.best_params_.get('n_estimators'))\n",
    "randomforest.fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaboost_fit(x_train, y_train, scoring='accuracy'):\n",
    "    decTree = DecisionTreeClassifier(random_state = 123)\n",
    "    adaboost = AdaBoostClassifier(base_estimator=decTree, random_state=123)\n",
    "    \n",
    "    hyperparam = {'base_estimator__min_samples_leaf': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n",
    "                  'learning_rate': [1., .1, .01, .001],\n",
    "                  'n_estimators': [100, 200, 300]}\n",
    "    \n",
    "    random_adaboost = RandomizedSearchCV(adaboost, param_distributions=hyperparam, cv = 5, n_iter = 1, \n",
    "                                        scoring = scoring, n_jobs = -1, random_state = 123)\n",
    "    \n",
    "    random_adaboost.fit(x_train, y_train)\n",
    "    \n",
    "    print('Best Accuracy: ', random_adaboost.best_score_)\n",
    "    print('Best Params: ', random_adaboost.best_params_)\n",
    "    return random_adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy:  0.601820354877\n",
      "Best Params:  {'n_estimators': 200, 'learning_rate': 1.0, 'base_estimator__min_samples_leaf': 41}\n"
     ]
    }
   ],
   "source": [
    "best_adaboost = adaboost_fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=41, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=200, random_state=123)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decTree_adaboost = DecisionTreeClassifier(min_samples_leaf = best_adaboost.best_params_.get('base_estimator__min_samples_leaf'),\n",
    "                                         random_state=123)\n",
    "adaBoost = AdaBoostClassifier(base_estimator=decTree_adaboost, \n",
    "                             n_estimators = best_adaboost.best_params_.get('n_estimators'),\n",
    "                             learning_rate = best_adaboost.best_params_.get('learning_rate'),\n",
    "                             random_state = 123)\n",
    "adaBoost.fit(x_train_standardize, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adaptive_boosting.pkl']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump best classifier\n",
    "joblib.dump(decTree,'decision_tree.pkl')\n",
    "joblib.dump(bagging,'bagging.pkl')\n",
    "joblib.dump(randomforest,'random_forest.pkl')\n",
    "joblib.dump(adaBoost,'adaptive_boosting.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testCategoricalDummies(data, categorical_columns, label_encoder, label_binarizer, dummy_columns):\n",
    "    data = data[categorical_columns].fillna(\"KOSONG\")\n",
    "    dummy_variables = pd.DataFrame()\n",
    "    \n",
    "    for i in categorical_columns:\n",
    "        label_en = label_encoder[i]\n",
    "        label_bin = label_binarizer[i]\n",
    "        \n",
    "        encoded = label_en.transform(data[i])\n",
    "        binary = label_bin.transform(encoded)\n",
    "        \n",
    "        if binary.shape[1] ==1:\n",
    "            dummy = pd.DataFrame(binary, index=data.index)\n",
    "        else:\n",
    "            dummy = pd.DataFrame(binary, index=data.index)\n",
    "            \n",
    "        dummy_variables = pd.concat([dummy_variables, dummy], axis=1)\n",
    "    dummy_variables.columns = dummy_columns\n",
    "    return dummy_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ValidData(data, numerical_columns, categorical_columns, imputer,\n",
    "             label_encoder, label_binarizer, dummy_columns, stemmer,\n",
    "             lemmatizer, vectorizer, standardizer):\n",
    "    data_numeric_imput = TransformImput(data[numerical_columns], imputer=imputer)\n",
    "    data_dummy = testCategoricalDummies(data, categorical_columns, label_encoder, label_binarizer, dummy_columns)\n",
    "    data_time = TimePreprocessing(data[\"tweet_created\"])\n",
    "    data_coord = CoordPreprocessing(data[\"tweet_coord\"])\n",
    "    data_text = TextPreprocessing(data[\"text\"], stemmer, lemmatizer)\n",
    "    text_feature = TransformText(data_text, vectorizer)\n",
    "    data_num = pd.concat([data_numeric_imput, data_time, data_coord, text_feature], axis=1)\n",
    "    data_standard = transformStandardize(data_num, standardizer)\n",
    "    data_valid = pd.concat([data_dummy, data_standard], axis=1)\n",
    "    return data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load necessary object\n",
    "# object = joblib.load(\"filename.pkl\")\n",
    "numerical_columns = joblib.load('numerical_col.pkl')\n",
    "categorical_columns = joblib.load('categorical_col.pkl')\n",
    "dummy_columns = joblib.load('dummy_col.pkl')\n",
    "\n",
    "imputer = joblib.load('imputer.pkl')\n",
    "label_binarizer = joblib.load('label_binarizer.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "standardizer = joblib.load('normalizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retweet_count    0\n",
      "dtype: int64\n",
      "       retweet_count\n",
      "8168             0.0\n",
      "13037            0.0\n",
      "8351             0.0\n",
      "8884             0.0\n",
      "13298            0.0\n",
      "       retweet_count      hour       day  latitude  longitude  americanair  \\\n",
      "8168       -0.104882  2.174833  1.115636 -0.454683  -0.219656    -0.264587   \n",
      "13037      -0.104882  1.139970  1.302381 -0.454683  -0.219656     1.669655   \n",
      "8351       -0.104882  0.680031  1.115636 -0.454683  -0.219656    -0.264587   \n",
      "8884       -0.104882  1.024986  1.022263 -0.454683  -0.219656    -0.264587   \n",
      "13298      -0.104882  0.680031  1.302381 -0.454683  -0.219656     3.504306   \n",
      "\n",
      "            bag    cancel    custom     delay    ...         need     plane  \\\n",
      "8168  -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146 -0.416764   \n",
      "13037 -0.254036  2.257301 -0.219469 -0.566082    ...    -0.262146 -0.416764   \n",
      "8351  -0.254036 -0.259219 -0.219469  2.678000    ...    -0.262146 -0.416764   \n",
      "8884  -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146 -0.416764   \n",
      "13298 -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146 -0.416764   \n",
      "\n",
      "         servic  southwestair     thank      time      unit  usairway  \\\n",
      "8168  -0.343903     -0.252026 -0.542242 -0.466184 -0.310905 -0.221934   \n",
      "13037 -0.343903     -0.252026 -0.542242 -0.466184 -0.310905 -0.221934   \n",
      "8351  -0.343903     -0.252026 -0.542242 -0.466184 -0.310905 -0.221934   \n",
      "8884  -0.343903     -0.252026  1.935850 -0.466184 -0.310905 -0.221934   \n",
      "13298 -0.343903     -0.252026 -0.542242 -0.466184 -0.310905 -0.221934   \n",
      "\n",
      "             wa      wait  \n",
      "8168  -2.316212 -9.644676  \n",
      "13037 -2.180931 -9.644676  \n",
      "8351  -2.316212 -9.644676  \n",
      "8884  -2.316212 -9.644676  \n",
      "13298 -2.316212 -9.259227  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# preprocess test data using validData()\n",
    "x_test_clean = ValidData(x_test, numerical_columns, categorical_columns, imputer, \n",
    "                         label_encoder, label_binarizer, dummy_columns, stemmer, \n",
    "                         lemmatizer, vectorizer, standardizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>need</th>\n",
       "      <th>plane</th>\n",
       "      <th>servic</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>thank</th>\n",
       "      <th>time</th>\n",
       "      <th>unit</th>\n",
       "      <th>usairway</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8168</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>2.174833</td>\n",
       "      <td>1.115636</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-2.316212</td>\n",
       "      <td>-9.644676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13037</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>1.139970</td>\n",
       "      <td>1.302381</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-2.180931</td>\n",
       "      <td>-9.644676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>0.680031</td>\n",
       "      <td>1.115636</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-2.316212</td>\n",
       "      <td>-9.644676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8884</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>1.024986</td>\n",
       "      <td>1.022263</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>1.935850</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-2.316212</td>\n",
       "      <td>-9.644676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104882</td>\n",
       "      <td>0.680031</td>\n",
       "      <td>1.302381</td>\n",
       "      <td>-0.454683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262146</td>\n",
       "      <td>-0.416764</td>\n",
       "      <td>-0.343903</td>\n",
       "      <td>-0.252026</td>\n",
       "      <td>-0.542242</td>\n",
       "      <td>-0.466184</td>\n",
       "      <td>-0.310905</td>\n",
       "      <td>-0.221934</td>\n",
       "      <td>-2.316212</td>\n",
       "      <td>-9.259227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "8168                  0              1                  0                   0   \n",
       "13037                 1              0                  0                   0   \n",
       "8351                  0              1                  0                   0   \n",
       "8884                  0              1                  0                   0   \n",
       "13298                 1              0                  0                   0   \n",
       "\n",
       "       airline_United  airline_Virgin America  retweet_count      hour  \\\n",
       "8168                0                       0      -0.104882  2.174833   \n",
       "13037               0                       0      -0.104882  1.139970   \n",
       "8351                0                       0      -0.104882  0.680031   \n",
       "8884                0                       0      -0.104882  1.024986   \n",
       "13298               0                       0      -0.104882  0.680031   \n",
       "\n",
       "            day  latitude    ...         need     plane    servic  \\\n",
       "8168   1.115636 -0.454683    ...    -0.262146 -0.416764 -0.343903   \n",
       "13037  1.302381 -0.454683    ...    -0.262146 -0.416764 -0.343903   \n",
       "8351   1.115636 -0.454683    ...    -0.262146 -0.416764 -0.343903   \n",
       "8884   1.022263 -0.454683    ...    -0.262146 -0.416764 -0.343903   \n",
       "13298  1.302381 -0.454683    ...    -0.262146 -0.416764 -0.343903   \n",
       "\n",
       "       southwestair     thank      time      unit  usairway        wa  \\\n",
       "8168      -0.252026 -0.542242 -0.466184 -0.310905 -0.221934 -2.316212   \n",
       "13037     -0.252026 -0.542242 -0.466184 -0.310905 -0.221934 -2.180931   \n",
       "8351      -0.252026 -0.542242 -0.466184 -0.310905 -0.221934 -2.316212   \n",
       "8884      -0.252026  1.935850 -0.466184 -0.310905 -0.221934 -2.316212   \n",
       "13298     -0.252026 -0.542242 -0.466184 -0.310905 -0.221934 -2.316212   \n",
       "\n",
       "           wait  \n",
       "8168  -9.644676  \n",
       "13037 -9.644676  \n",
       "8351  -9.644676  \n",
       "8884  -9.644676  \n",
       "13298 -9.259227  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('decision_tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5730832873690016"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a single tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictData(classifier, input_columns, numerical_columns, categorical_columns, imputer, label_encoder, label_binarizer, dummy_columns, stemmer, lemmatizer, vectorizer, standardizer):\n",
    "    raw_data = pd.Series([])\n",
    "    for i in range(0,len(input_columns)):\n",
    "        message = \"Masukkan nilai untuk kolom : \"+str(input_columns[i])+\" \"\n",
    "        raw_data[i] = input(message)\n",
    "    data = pd.DataFrame(raw_data)\n",
    "    data = data.transpose()\n",
    "    data.columns = input_columns\n",
    "    for i in numerical_columns :\n",
    "        data[i] = pd.to_numeric(data[i])\n",
    "    \n",
    "    # preprocess the data using validData()\n",
    "    data_clean = ValidData(data, numerical_columns, categorical_columns, imputer, label_encoder, label_binarizer, dummy_columns, stemmer, lemmatizer, vectorizer, standardizer)\n",
    "    \n",
    "    result = classifier.predict(data_clean)\n",
    "    print(result)\n",
    "    print(classifier.predict_proba(data_clean))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load necessary object\n",
    "# object = joblib.load(\"filename.pkl\")\n",
    "classifier = joblib.load('decision_tree.pkl')\n",
    "input_columns = joblib.load('input_col.pkl')\n",
    "numerical_columns = joblib.load('numerical_col.pkl')\n",
    "categorical_columns = joblib.load('categorical_col.pkl')\n",
    "dummy_columns = joblib.load('dummy_col.pkl')\n",
    "\n",
    "imputer = joblib.load('imputer.pkl')\n",
    "label_binarizer = joblib.load('label_binarizer.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "standardizer = joblib.load('normalizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For instance, say we wanna predict this tweet sentiment :<br>\n",
    "<table>\n",
    "<tr> <td>airline </td><td>  US Airways</td></tr>\n",
    "<tr> <td>retweet_count </td><td>  0</td></tr>\n",
    "<tr> <td>text </td><td>@USAirways @AmericanAir 2 trips in a row with missing luggage. Just like last time. I pay for baggage to be transported.</td></tr>\n",
    "<tr> <td>tweet_coord </td><td>  [0.0, 0.0]</td></tr>\n",
    "<tr> <td>tweet_created </td><td>  2015-02-18 19:17:59 -0800</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir here is my conf #F8NEQM. My flight was delayed for 3 hours while my friend waited for me on her bday. Please follow up.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 19:15:22 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir - STL-BOS flight today was Cancelled Flightled. Online resched form gives an error. On hold for past 90 min. HELP! #terribleservice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 07:14:07 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united I would like to know what's going on before his current flight lands.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 22:57:20 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9626</th>\n",
       "      <td>US Airways</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways flight 435 is delayed so will miss connecting flight 457 can you please help with alternate? Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 00:33:04 -0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>American</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir - Please find my bag!! In Singapore for three days already without my bag. Last known destination LAX Tag: 580815 Please help.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:28:08 -0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          airline  retweet_count  \\\n",
       "4532    Southwest              0   \n",
       "5387    Southwest              0   \n",
       "732        United              0   \n",
       "9626   US Airways              0   \n",
       "11944    American              0   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "4532               @SouthwestAir here is my conf #F8NEQM. My flight was delayed for 3 hours while my friend waited for me on her bday. Please follow up.   \n",
       "5387   @SouthwestAir - STL-BOS flight today was Cancelled Flightled. Online resched form gives an error. On hold for past 90 min. HELP! #terribleservice   \n",
       "732                                                                        @united I would like to know what's going on before his current flight lands.   \n",
       "9626                                  @USAirways flight 435 is delayed so will miss connecting flight 457 can you please help with alternate? Thank you.   \n",
       "11944        @AmericanAir - Please find my bag!! In Singapore for three days already without my bag. Last known destination LAX Tag: 580815 Please help.   \n",
       "\n",
       "      tweet_coord              tweet_created  \n",
       "4532          NaN  2015-02-23 19:15:22 -0800  \n",
       "5387          NaN  2015-02-21 07:14:07 -0800  \n",
       "732           NaN  2015-02-23 22:57:20 -0800  \n",
       "9626          NaN  2015-02-23 00:33:04 -0800  \n",
       "11944         NaN  2015-02-24 10:28:08 -0800  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masukkan nilai untuk kolom : airline US Airways\n",
      "Masukkan nilai untuk kolom : retweet_count 0\n",
      "Masukkan nilai untuk kolom : text @USAirways @AmericanAir 2 trips in a row with missing luggage. Just like last time. I pay for baggage to be transported.\n",
      "Masukkan nilai untuk kolom : tweet_coord 0.0, 0.0\n",
      "Masukkan nilai untuk kolom : tweet_created 2015-02-18 19:17:59 -0800\n",
      "retweet_count    0\n",
      "dtype: int64\n",
      "   retweet_count\n",
      "0            0.0\n",
      "   retweet_count      hour      day  latitude  longitude  americanair  \\\n",
      "0      -0.104882  1.944864  1.06895 -0.454683  -0.219656     2.540681   \n",
      "\n",
      "        bag    cancel    custom     delay    ...         need     plane  \\\n",
      "0 -0.254036 -0.259219 -0.219469 -0.566082    ...    -0.262146 -0.416764   \n",
      "\n",
      "     servic  southwestair     thank      time      unit  usairway        wa  \\\n",
      "0 -0.343903     -0.252026 -0.542242  1.716009 -0.310905  2.602809 -2.316212   \n",
      "\n",
      "       wait  \n",
      "0 -9.644676  \n",
      "\n",
      "[1 rows x 27 columns]\n",
      "['negative']\n",
      "[[ 0.87804878  0.09756098  0.02439024]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call predictData()\n",
    "predictData(classifier, input_columns, numerical_columns, categorical_columns, \n",
    "            imputer, label_encoder, label_binarizer, dummy_columns, stemmer, \n",
    "            lemmatizer, vectorizer, standardizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENVNAME]",
   "language": "python",
   "name": "conda-env-ENVNAME-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

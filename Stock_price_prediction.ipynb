{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://www.kaggle.com/numerai/encrypted-stock-market-data-from-numerai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('numerai_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.58268</td>\n",
       "      <td>0.57387</td>\n",
       "      <td>0.47334</td>\n",
       "      <td>0.43624</td>\n",
       "      <td>0.51407</td>\n",
       "      <td>0.56079</td>\n",
       "      <td>0.48107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.58190</td>\n",
       "      <td>0.52786</td>\n",
       "      <td>0.46630</td>\n",
       "      <td>0.39546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112648</td>\n",
       "      <td>0.51490</td>\n",
       "      <td>0.57116</td>\n",
       "      <td>0.54893</td>\n",
       "      <td>0.54678</td>\n",
       "      <td>0.48280</td>\n",
       "      <td>0.50677</td>\n",
       "      <td>0.48026</td>\n",
       "      <td>0.46114</td>\n",
       "      <td>0.33667</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.53465</td>\n",
       "      <td>0.54336</td>\n",
       "      <td>0.42988</td>\n",
       "      <td>0.35608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142854</td>\n",
       "      <td>0.52758</td>\n",
       "      <td>0.52880</td>\n",
       "      <td>0.59754</td>\n",
       "      <td>0.44720</td>\n",
       "      <td>0.40589</td>\n",
       "      <td>0.46379</td>\n",
       "      <td>0.60392</td>\n",
       "      <td>0.44801</td>\n",
       "      <td>0.33079</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.60216</td>\n",
       "      <td>0.58529</td>\n",
       "      <td>0.47515</td>\n",
       "      <td>0.44429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131074</td>\n",
       "      <td>0.59609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54468</td>\n",
       "      <td>0.44602</td>\n",
       "      <td>0.45216</td>\n",
       "      <td>0.46244</td>\n",
       "      <td>0.51467</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>0.54993</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.56061</td>\n",
       "      <td>0.43781</td>\n",
       "      <td>0.55344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26355</td>\n",
       "      <td>0.55105</td>\n",
       "      <td>0.43209</td>\n",
       "      <td>0.61949</td>\n",
       "      <td>0.36115</td>\n",
       "      <td>0.37597</td>\n",
       "      <td>0.44154</td>\n",
       "      <td>0.62260</td>\n",
       "      <td>0.45039</td>\n",
       "      <td>0.44299</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.64087</td>\n",
       "      <td>0.53343</td>\n",
       "      <td>0.56798</td>\n",
       "      <td>0.58223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0   23288       NaN   0.58268   0.57387   0.47334   0.43624   0.51407   \n",
       "1  112648   0.51490   0.57116   0.54893   0.54678   0.48280   0.50677   \n",
       "2  142854   0.52758   0.52880   0.59754   0.44720   0.40589   0.46379   \n",
       "3  131074   0.59609       NaN   0.54468   0.44602   0.45216   0.46244   \n",
       "4   26355   0.55105   0.43209   0.61949   0.36115   0.37597   0.44154   \n",
       "\n",
       "   feature7  feature8  feature9   ...    feature13  feature14  feature15  \\\n",
       "0   0.56079   0.48107       NaN   ...       medium     medium     medium   \n",
       "1   0.48026   0.46114   0.33667   ...       medium     medium     medium   \n",
       "2   0.60392   0.44801   0.33079   ...       medium       high     medium   \n",
       "3   0.51467   0.42857   0.54993   ...       medium        NaN     medium   \n",
       "4   0.62260   0.45039   0.44299   ...       medium     medium     medium   \n",
       "\n",
       "  feature16 feature17 feature18 feature19 feature20  feature21  target  \n",
       "0    medium    medium   0.58190   0.52786   0.46630    0.39546       1  \n",
       "1    medium    medium   0.53465   0.54336   0.42988    0.35608       1  \n",
       "2    medium    medium   0.60216   0.58529   0.47515    0.44429       1  \n",
       "3    medium    medium   0.56061   0.43781   0.55344        NaN       0  \n",
       "4    medium    medium   0.64087   0.53343   0.56798    0.58223       1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65043, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "feature1     2055\n",
       "feature2     2658\n",
       "feature3      200\n",
       "feature4      992\n",
       "feature5     1662\n",
       "feature6     2835\n",
       "feature7     1249\n",
       "feature8     2933\n",
       "feature9     2945\n",
       "feature10     815\n",
       "feature11    1388\n",
       "feature12    2117\n",
       "feature13     244\n",
       "feature14    2070\n",
       "feature15    1034\n",
       "feature16    1440\n",
       "feature17     343\n",
       "feature18    1349\n",
       "feature19    1885\n",
       "feature20     307\n",
       "feature21    2265\n",
       "target          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135166    1\n",
      "39686     1\n",
      "29467     1\n",
      "31514     1\n",
      "25369     1\n",
      "27416     1\n",
      "4887      1\n",
      "2836      1\n",
      "15122     1\n",
      "54031     1\n",
      "51980     1\n",
      "62219     1\n",
      "64266     1\n",
      "58121     1\n",
      "60168     1\n",
      "45827     1\n",
      "107297    1\n",
      "43776     1\n",
      "88830     1\n",
      "92920     1\n",
      "70391     1\n",
      "66293     1\n",
      "80626     1\n",
      "74481     1\n",
      "119535    1\n",
      "129770    1\n",
      "123625    1\n",
      "125672    1\n",
      "105190    1\n",
      "99045     1\n",
      "         ..\n",
      "1642      1\n",
      "134763    1\n",
      "13996     1\n",
      "3755      1\n",
      "132778    1\n",
      "28327     1\n",
      "18082     1\n",
      "153248    1\n",
      "104088    1\n",
      "124566    1\n",
      "118419    1\n",
      "120464    1\n",
      "75406     1\n",
      "81549     1\n",
      "67210     1\n",
      "73353     1\n",
      "71304     1\n",
      "85635     1\n",
      "83586     1\n",
      "87680     1\n",
      "42622     1\n",
      "48765     1\n",
      "46716     1\n",
      "36475     1\n",
      "149663    1\n",
      "56945     1\n",
      "11887     1\n",
      "140910    1\n",
      "145004    1\n",
      "133121    1\n",
      "Name: id, Length: 65043, dtype: int64 \n",
      "\n",
      "\n",
      "0.49185    13\n",
      "0.45108    13\n",
      "0.48870    12\n",
      "0.49018    12\n",
      "0.51909    12\n",
      "0.48381    12\n",
      "0.47949    12\n",
      "0.47431    11\n",
      "0.47359    11\n",
      "0.50800    11\n",
      "0.47701    11\n",
      "0.48504    11\n",
      "0.49318    11\n",
      "0.50761    11\n",
      "0.49475    11\n",
      "0.50178    10\n",
      "0.48260    10\n",
      "0.49305    10\n",
      "0.48060    10\n",
      "0.48873    10\n",
      "0.47339    10\n",
      "0.50759    10\n",
      "0.50896    10\n",
      "0.50811    10\n",
      "0.49434    10\n",
      "0.46656    10\n",
      "0.49148    10\n",
      "0.49574    10\n",
      "0.50435    10\n",
      "0.48668    10\n",
      "           ..\n",
      "0.66869     1\n",
      "0.25745     1\n",
      "0.40344     1\n",
      "0.42601     1\n",
      "0.32840     1\n",
      "0.38536     1\n",
      "0.40637     1\n",
      "0.66041     1\n",
      "0.56304     1\n",
      "0.55484     1\n",
      "0.39115     1\n",
      "0.62089     1\n",
      "0.43899     1\n",
      "0.38603     1\n",
      "0.33292     1\n",
      "0.59321     1\n",
      "0.56073     1\n",
      "0.18652     1\n",
      "0.46355     1\n",
      "0.59810     1\n",
      "0.41250     1\n",
      "0.28149     1\n",
      "0.60678     1\n",
      "0.61878     1\n",
      "0.22190     1\n",
      "0.24684     1\n",
      "0.59076     1\n",
      "0.35859     1\n",
      "0.36023     1\n",
      "0.28125     1\n",
      "Name: feature1, Length: 28195, dtype: int64 \n",
      "\n",
      "\n",
      "0.53308    10\n",
      "0.50351    10\n",
      "0.58289    10\n",
      "0.53764     9\n",
      "0.46185     9\n",
      "0.48496     9\n",
      "0.57297     9\n",
      "0.55836     9\n",
      "0.52133     9\n",
      "0.56411     9\n",
      "0.52695     9\n",
      "0.54061     9\n",
      "0.49135     9\n",
      "0.53071     9\n",
      "0.51486     8\n",
      "0.55464     8\n",
      "0.51800     8\n",
      "0.50029     8\n",
      "0.58522     8\n",
      "0.56249     8\n",
      "0.54611     8\n",
      "0.53189     8\n",
      "0.59665     8\n",
      "0.57252     8\n",
      "0.48234     8\n",
      "0.59983     8\n",
      "0.52984     8\n",
      "0.57445     8\n",
      "0.43035     8\n",
      "0.40997     8\n",
      "           ..\n",
      "0.72330     1\n",
      "0.77106     1\n",
      "0.55729     1\n",
      "0.65163     1\n",
      "0.58892     1\n",
      "0.29108     1\n",
      "0.38479     1\n",
      "0.38098     1\n",
      "0.36729     1\n",
      "0.38557     1\n",
      "0.45197     1\n",
      "0.52681     1\n",
      "0.75647     1\n",
      "0.48713     1\n",
      "0.41181     1\n",
      "0.67162     1\n",
      "0.61470     1\n",
      "0.44141     1\n",
      "0.28615     1\n",
      "0.70040     1\n",
      "0.70495     1\n",
      "0.46955     1\n",
      "0.72262     1\n",
      "0.34763     1\n",
      "0.36144     1\n",
      "0.68312     1\n",
      "0.74894     1\n",
      "0.65344     1\n",
      "0.40744     1\n",
      "0.18050     1\n",
      "Name: feature2, Length: 31180, dtype: int64 \n",
      "\n",
      "\n",
      "0.60388    12\n",
      "0.60440    12\n",
      "0.59799    12\n",
      "0.62159    11\n",
      "0.60020    11\n",
      "0.58768    11\n",
      "0.51622    10\n",
      "0.56834    10\n",
      "0.59292    10\n",
      "0.62631    10\n",
      "0.50838    10\n",
      "0.59043    10\n",
      "0.62662    10\n",
      "0.61029    10\n",
      "0.56485    10\n",
      "0.57366    10\n",
      "0.55858    10\n",
      "0.61699    10\n",
      "0.60800    10\n",
      "0.60429     9\n",
      "0.57681     9\n",
      "0.60114     9\n",
      "0.61432     9\n",
      "0.57336     9\n",
      "0.59551     9\n",
      "0.59334     9\n",
      "0.59315     9\n",
      "0.56614     9\n",
      "0.61137     9\n",
      "0.57259     9\n",
      "           ..\n",
      "0.80256     1\n",
      "0.40337     1\n",
      "0.72062     1\n",
      "0.78303     1\n",
      "0.08201     1\n",
      "0.71550     1\n",
      "0.73664     1\n",
      "0.59712     1\n",
      "0.32260     1\n",
      "0.63662     1\n",
      "0.50373     1\n",
      "0.58199     1\n",
      "0.34715     1\n",
      "0.68072     1\n",
      "0.74450     1\n",
      "0.59943     1\n",
      "0.43301     1\n",
      "0.33276     1\n",
      "0.67921     1\n",
      "0.93728     1\n",
      "0.66561     1\n",
      "0.65861     1\n",
      "0.49674     1\n",
      "0.44286     1\n",
      "0.43532     1\n",
      "0.43700     1\n",
      "0.50328     1\n",
      "0.26935     1\n",
      "0.83028     1\n",
      "0.44035     1\n",
      "Name: feature3, Length: 30294, dtype: int64 \n",
      "\n",
      "\n",
      "0.45042    10\n",
      "0.49161    10\n",
      "0.45604    10\n",
      "0.41787    10\n",
      "0.41922    10\n",
      "0.46681    10\n",
      "0.48075    10\n",
      "0.45697    10\n",
      "0.43946    10\n",
      "0.47808    10\n",
      "0.46809     9\n",
      "0.46953     9\n",
      "0.46777     9\n",
      "0.48162     9\n",
      "0.44182     9\n",
      "0.44170     9\n",
      "0.48143     9\n",
      "0.45057     9\n",
      "0.47066     9\n",
      "0.48801     9\n",
      "0.45360     9\n",
      "0.47191     9\n",
      "0.45949     9\n",
      "0.48043     9\n",
      "0.47823     9\n",
      "0.43810     9\n",
      "0.42988     9\n",
      "0.49280     9\n",
      "0.44611     9\n",
      "0.46524     9\n",
      "           ..\n",
      "0.28035     1\n",
      "0.42204     1\n",
      "0.54293     1\n",
      "0.27784     1\n",
      "0.26521     1\n",
      "0.32915     1\n",
      "0.61763     1\n",
      "0.61845     1\n",
      "0.36758     1\n",
      "0.34048     1\n",
      "0.42872     1\n",
      "0.53765     1\n",
      "0.42743     1\n",
      "0.52067     1\n",
      "0.22894     1\n",
      "0.25577     1\n",
      "0.25852     1\n",
      "0.45573     1\n",
      "0.55590     1\n",
      "0.68991     1\n",
      "0.45267     1\n",
      "0.57974     1\n",
      "0.47384     1\n",
      "0.66402     1\n",
      "0.30545     1\n",
      "0.51801     1\n",
      "0.55456     1\n",
      "0.39562     1\n",
      "0.38187     1\n",
      "0.37172     1\n",
      "Name: feature4, Length: 30144, dtype: int64 \n",
      "\n",
      "\n",
      "0.42244    12\n",
      "0.45737    11\n",
      "0.41669    11\n",
      "0.41985    11\n",
      "0.43218    10\n",
      "0.38959    10\n",
      "0.43597    10\n",
      "0.44388    10\n",
      "0.43173    10\n",
      "0.41097    10\n",
      "0.46043    10\n",
      "0.43330    10\n",
      "0.40134    10\n",
      "0.39260     9\n",
      "0.45976     9\n",
      "0.40502     9\n",
      "0.43097     9\n",
      "0.41066     9\n",
      "0.38996     9\n",
      "0.47741     9\n",
      "0.41899     9\n",
      "0.43945     9\n",
      "0.44721     9\n",
      "0.46896     9\n",
      "0.40710     9\n",
      "0.45571     9\n",
      "0.44517     9\n",
      "0.46230     9\n",
      "0.40777     9\n",
      "0.41164     9\n",
      "           ..\n",
      "0.62428     1\n",
      "0.34217     1\n",
      "0.61721     1\n",
      "0.31066     1\n",
      "0.58525     1\n",
      "0.54860     1\n",
      "0.58547     1\n",
      "0.15072     1\n",
      "0.54208     1\n",
      "0.39875     1\n",
      "0.59115     1\n",
      "0.43764     1\n",
      "0.54594     1\n",
      "0.78244     1\n",
      "0.38136     1\n",
      "0.51087     1\n",
      "0.29615     1\n",
      "0.26650     1\n",
      "0.62401     1\n",
      "0.34757     1\n",
      "0.63149     1\n",
      "0.24941     1\n",
      "0.20068     1\n",
      "0.69105     1\n",
      "0.46701     1\n",
      "0.36041     1\n",
      "0.54291     1\n",
      "0.28623     1\n",
      "0.51713     1\n",
      "0.50000     1\n",
      "Name: feature5, Length: 28740, dtype: int64 \n",
      "\n",
      "\n",
      "0.54354    11\n",
      "0.47678    10\n",
      "0.53852    10\n",
      "0.51101    10\n",
      "0.51641    10\n",
      "0.50545     9\n",
      "0.48705     9\n",
      "0.49577     9\n",
      "0.49876     9\n",
      "0.44833     9\n",
      "0.49621     9\n",
      "0.46764     9\n",
      "0.44484     9\n",
      "0.48793     9\n",
      "0.49365     9\n",
      "0.56116     9\n",
      "0.49924     9\n",
      "0.45424     8\n",
      "0.48905     8\n",
      "0.51454     8\n",
      "0.49296     8\n",
      "0.46524     8\n",
      "0.49949     8\n",
      "0.51687     8\n",
      "0.51994     8\n",
      "0.44483     8\n",
      "0.50277     8\n",
      "0.52623     8\n",
      "0.47518     8\n",
      "0.51652     8\n",
      "           ..\n",
      "0.60609     1\n",
      "0.77239     1\n",
      "0.54839     1\n",
      "0.30946     1\n",
      "0.59543     1\n",
      "0.63505     1\n",
      "0.58994     1\n",
      "0.62628     1\n",
      "0.33116     1\n",
      "0.35755     1\n",
      "0.43949     1\n",
      "0.36581     1\n",
      "0.28190     1\n",
      "0.69003     1\n",
      "0.68057     1\n",
      "0.13891     1\n",
      "0.22325     1\n",
      "0.38869     1\n",
      "0.37366     1\n",
      "0.47933     1\n",
      "0.65344     1\n",
      "0.35015     1\n",
      "0.53763     1\n",
      "0.73763     1\n",
      "0.38188     1\n",
      "0.33195     1\n",
      "0.38891     1\n",
      "0.77024     1\n",
      "0.17803     1\n",
      "0.37172     1\n",
      "Name: feature6, Length: 31108, dtype: int64 \n",
      "\n",
      "\n",
      "0.52501    14\n",
      "0.56054    11\n",
      "0.54838    11\n",
      "0.54530    11\n",
      "0.54705    11\n",
      "0.54527    10\n",
      "0.54080    10\n",
      "0.52633    10\n",
      "0.54268    10\n",
      "0.53930    10\n",
      "0.53400    10\n",
      "0.53697    10\n",
      "0.55289    10\n",
      "0.55341    10\n",
      "0.55752    10\n",
      "0.49369    10\n",
      "0.54209    10\n",
      "0.56401    10\n",
      "0.52884    10\n",
      "0.53988    10\n",
      "0.55710    10\n",
      "0.54039    10\n",
      "0.52684    10\n",
      "0.58239    10\n",
      "0.52739     9\n",
      "0.57439     9\n",
      "0.56126     9\n",
      "0.54088     9\n",
      "0.57858     9\n",
      "0.51883     9\n",
      "           ..\n",
      "0.67129     1\n",
      "0.86746     1\n",
      "0.40833     1\n",
      "0.35694     1\n",
      "0.70803     1\n",
      "0.32105     1\n",
      "0.70944     1\n",
      "0.34812     1\n",
      "0.68920     1\n",
      "0.49326     1\n",
      "0.41293     1\n",
      "0.73485     1\n",
      "0.40022     1\n",
      "0.25929     1\n",
      "0.64969     1\n",
      "0.61203     1\n",
      "0.65773     1\n",
      "0.65865     1\n",
      "0.70452     1\n",
      "0.22705     1\n",
      "0.29057     1\n",
      "0.35151     1\n",
      "0.47670     1\n",
      "0.65698     1\n",
      "0.41807     1\n",
      "0.80584     1\n",
      "0.65161     1\n",
      "0.32950     1\n",
      "0.80410     1\n",
      "0.51520     1\n",
      "Name: feature7, Length: 30130, dtype: int64 \n",
      "\n",
      "\n",
      "0.47539    12\n",
      "0.50542    12\n",
      "0.49278    12\n",
      "0.52087    12\n",
      "0.46252    11\n",
      "0.44979    11\n",
      "0.48654    11\n",
      "0.48189    11\n",
      "0.45984    11\n",
      "0.47979    11\n",
      "0.50401    11\n",
      "0.49498    11\n",
      "0.48634    10\n",
      "0.46717    10\n",
      "0.50646    10\n",
      "0.47409    10\n",
      "0.44465    10\n",
      "0.47156    10\n",
      "0.46892    10\n",
      "0.47820    10\n",
      "0.44967    10\n",
      "0.44857    10\n",
      "0.49058    10\n",
      "0.45753    10\n",
      "0.48298    10\n",
      "0.47945    10\n",
      "0.50663    10\n",
      "0.49426    10\n",
      "0.46521    10\n",
      "0.48434    10\n",
      "           ..\n",
      "0.64843     1\n",
      "0.55761     1\n",
      "0.64130     1\n",
      "0.56101     1\n",
      "0.41064     1\n",
      "0.60322     1\n",
      "0.89207     1\n",
      "0.37845     1\n",
      "0.34974     1\n",
      "0.27288     1\n",
      "0.32050     1\n",
      "0.36170     1\n",
      "0.26237     1\n",
      "0.25727     1\n",
      "0.25864     1\n",
      "0.60548     1\n",
      "0.31957     1\n",
      "0.54143     1\n",
      "0.34941     1\n",
      "0.34925     1\n",
      "0.65678     1\n",
      "0.70547     1\n",
      "0.52551     1\n",
      "0.44158     1\n",
      "0.79243     1\n",
      "0.85152     1\n",
      "0.58111     1\n",
      "0.52143     1\n",
      "0.63181     1\n",
      "0.54854     1\n",
      "Name: feature8, Length: 27721, dtype: int64 \n",
      "\n",
      "\n",
      "0.34312    11\n",
      "0.30536    10\n",
      "0.31622    10\n",
      "0.32003    10\n",
      "0.25704    10\n",
      "0.32557     9\n",
      "0.29928     9\n",
      "0.29567     9\n",
      "0.26049     9\n",
      "0.30583     9\n",
      "0.33543     9\n",
      "0.32993     9\n",
      "0.27641     9\n",
      "0.29011     9\n",
      "0.39698     9\n",
      "0.30897     8\n",
      "0.32103     8\n",
      "0.34530     8\n",
      "0.29396     8\n",
      "0.32808     8\n",
      "0.32862     8\n",
      "0.31353     8\n",
      "0.28123     8\n",
      "0.36926     8\n",
      "0.34726     8\n",
      "0.33580     8\n",
      "0.29253     8\n",
      "0.31488     8\n",
      "0.32674     8\n",
      "0.33056     8\n",
      "           ..\n",
      "0.39342     1\n",
      "0.13292     1\n",
      "0.22903     1\n",
      "0.59905     1\n",
      "0.43899     1\n",
      "0.51216     1\n",
      "0.50612     1\n",
      "0.48698     1\n",
      "0.26447     1\n",
      "0.13871     1\n",
      "0.59998     1\n",
      "0.20625     1\n",
      "0.47962     1\n",
      "0.37524     1\n",
      "0.32326     1\n",
      "0.42750     1\n",
      "0.44174     1\n",
      "0.44250     1\n",
      "0.49519     1\n",
      "0.44660     1\n",
      "0.62298     1\n",
      "0.40703     1\n",
      "0.47041     1\n",
      "0.48795     1\n",
      "0.29814     1\n",
      "0.47881     1\n",
      "0.56766     1\n",
      "0.42497     1\n",
      "0.49839     1\n",
      "0.35689     1\n",
      "Name: feature9, Length: 30207, dtype: int64 \n",
      "\n",
      "\n",
      "0.58709    10\n",
      "0.59254    10\n",
      "0.56346    10\n",
      "0.63151    10\n",
      "0.56889    10\n",
      "0.50772    10\n",
      "0.63158    10\n",
      "0.56222     9\n",
      "0.57584     9\n",
      "0.60334     9\n",
      "0.61907     9\n",
      "0.56709     9\n",
      "0.55838     9\n",
      "0.58897     9\n",
      "0.55415     9\n",
      "0.57990     9\n",
      "0.63372     9\n",
      "0.58264     9\n",
      "0.56380     9\n",
      "0.55804     9\n",
      "0.59599     9\n",
      "0.57927     9\n",
      "0.63024     9\n",
      "0.54260     9\n",
      "0.54066     9\n",
      "0.57221     8\n",
      "0.59926     8\n",
      "0.59761     8\n",
      "0.57007     8\n",
      "0.53508     8\n",
      "           ..\n",
      "0.64896     1\n",
      "0.80334     1\n",
      "0.55793     1\n",
      "0.44344     1\n",
      "0.38474     1\n",
      "0.77929     1\n",
      "0.32593     1\n",
      "0.77806     1\n",
      "0.71173     1\n",
      "0.49017     1\n",
      "0.41183     1\n",
      "0.46958     1\n",
      "0.83702     1\n",
      "0.25436     1\n",
      "0.62652     1\n",
      "0.60531     1\n",
      "0.61133     1\n",
      "0.52094     1\n",
      "0.75062     1\n",
      "0.73576     1\n",
      "0.46927     1\n",
      "0.48025     1\n",
      "0.53591     1\n",
      "0.62808     1\n",
      "0.67341     1\n",
      "0.55306     1\n",
      "0.41012     1\n",
      "0.39973     1\n",
      "0.73293     1\n",
      "0.69158     1\n",
      "Name: feature10, Length: 30110, dtype: int64 \n",
      "\n",
      "\n",
      "0.41529    11\n",
      "0.41346    11\n",
      "0.39710    10\n",
      "0.43273    10\n",
      "0.43977    10\n",
      "0.43835    10\n",
      "0.43938    10\n",
      "0.43417    10\n",
      "0.43310    10\n",
      "0.43455    10\n",
      "0.45911     9\n",
      "0.40085     9\n",
      "0.42970     9\n",
      "0.42730     9\n",
      "0.40826     9\n",
      "0.41037     9\n",
      "0.42657     9\n",
      "0.42324     9\n",
      "0.42790     9\n",
      "0.41228     9\n",
      "0.40594     9\n",
      "0.41857     9\n",
      "0.34440     9\n",
      "0.42757     9\n",
      "0.39307     9\n",
      "0.46347     9\n",
      "0.39299     9\n",
      "0.45535     9\n",
      "0.49655     9\n",
      "0.41649     9\n",
      "           ..\n",
      "0.36955     1\n",
      "0.28878     1\n",
      "0.30898     1\n",
      "0.53688     1\n",
      "0.54826     1\n",
      "0.74229     1\n",
      "0.67956     1\n",
      "0.39813     1\n",
      "0.59381     1\n",
      "0.36822     1\n",
      "0.44992     1\n",
      "0.34371     1\n",
      "0.53497     1\n",
      "0.86217     1\n",
      "0.66124     1\n",
      "0.51001     1\n",
      "0.60286     1\n",
      "0.22241     1\n",
      "0.58064     1\n",
      "0.41435     1\n",
      "0.60710     1\n",
      "0.42999     1\n",
      "0.23625     1\n",
      "0.51266     1\n",
      "0.46586     1\n",
      "0.40603     1\n",
      "0.33140     1\n",
      "0.20810     1\n",
      "0.52943     1\n",
      "0.28327     1\n",
      "Name: feature11, Length: 30010, dtype: int64 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45933    11\n",
      "0.42944    10\n",
      "0.49667    10\n",
      "0.45443    10\n",
      "0.48419    10\n",
      "0.43849    10\n",
      "0.49452    10\n",
      "0.48874     9\n",
      "0.48830     9\n",
      "0.47991     9\n",
      "0.48736     9\n",
      "0.45806     9\n",
      "0.41061     9\n",
      "0.43695     9\n",
      "0.52606     9\n",
      "0.45097     9\n",
      "0.48941     9\n",
      "0.50757     9\n",
      "0.48268     9\n",
      "0.50091     9\n",
      "0.49168     9\n",
      "0.45999     9\n",
      "0.50196     9\n",
      "0.47604     8\n",
      "0.49371     8\n",
      "0.52757     8\n",
      "0.46439     8\n",
      "0.46843     8\n",
      "0.50382     8\n",
      "0.45814     8\n",
      "           ..\n",
      "0.32252     1\n",
      "0.74137     1\n",
      "0.38869     1\n",
      "0.55231     1\n",
      "0.72461     1\n",
      "0.63023     1\n",
      "0.37185     1\n",
      "0.59795     1\n",
      "0.55276     1\n",
      "0.43788     1\n",
      "0.65851     1\n",
      "0.59253     1\n",
      "0.24036     1\n",
      "0.77782     1\n",
      "0.54167     1\n",
      "0.32268     1\n",
      "0.35606     1\n",
      "0.20903     1\n",
      "0.74642     1\n",
      "0.56067     1\n",
      "0.60517     1\n",
      "0.53714     1\n",
      "0.71296     1\n",
      "0.26266     1\n",
      "0.19823     1\n",
      "0.60797     1\n",
      "0.67442     1\n",
      "0.36158     1\n",
      "0.28987     1\n",
      "0.37172     1\n",
      "Name: feature12, Length: 31053, dtype: int64 \n",
      "\n",
      "\n",
      "medium    55668\n",
      "low        8232\n",
      "high        899\n",
      "Name: feature13, dtype: int64 \n",
      "\n",
      "\n",
      "medium    44460\n",
      "high      18368\n",
      "low         145\n",
      "Name: feature14, dtype: int64 \n",
      "\n",
      "\n",
      "medium    58120\n",
      "high       4403\n",
      "low        1486\n",
      "Name: feature15, dtype: int64 \n",
      "\n",
      "\n",
      "medium    52863\n",
      "low       10272\n",
      "high        468\n",
      "Name: feature16, dtype: int64 \n",
      "\n",
      "\n",
      "medium    56138\n",
      "high       7582\n",
      "low         980\n",
      "Name: feature17, dtype: int64 \n",
      "\n",
      "\n",
      "0.59739    11\n",
      "0.61234    11\n",
      "0.58244    11\n",
      "0.58325    11\n",
      "0.60195    10\n",
      "0.58691    10\n",
      "0.60683    10\n",
      "0.60618    10\n",
      "0.60191    10\n",
      "0.54688    10\n",
      "0.60825    10\n",
      "0.59919    10\n",
      "0.60182    10\n",
      "0.55392    10\n",
      "0.60717    10\n",
      "0.62181    10\n",
      "0.59698     9\n",
      "0.54835     9\n",
      "0.59142     9\n",
      "0.56716     9\n",
      "0.60494     9\n",
      "0.54854     9\n",
      "0.59178     9\n",
      "0.58127     9\n",
      "0.56990     9\n",
      "0.61275     9\n",
      "0.57098     9\n",
      "0.59612     9\n",
      "0.58470     9\n",
      "0.58949     9\n",
      "           ..\n",
      "0.56946     1\n",
      "0.41019     1\n",
      "0.83255     1\n",
      "0.65070     1\n",
      "0.53466     1\n",
      "0.60438     1\n",
      "0.79130     1\n",
      "0.64595     1\n",
      "0.71535     1\n",
      "0.44901     1\n",
      "0.47578     1\n",
      "0.58526     1\n",
      "0.66041     1\n",
      "0.66584     1\n",
      "0.74608     1\n",
      "0.43451     1\n",
      "0.71876     1\n",
      "0.50712     1\n",
      "0.64365     1\n",
      "0.46355     1\n",
      "0.67665     1\n",
      "0.30932     1\n",
      "0.46995     1\n",
      "0.59321     1\n",
      "0.67144     1\n",
      "0.66155     1\n",
      "0.43899     1\n",
      "0.78230     1\n",
      "0.72422     1\n",
      "1.00000     1\n",
      "Name: feature18, Length: 29956, dtype: int64 \n",
      "\n",
      "\n",
      "0.53068    11\n",
      "0.54618    11\n",
      "0.53304    10\n",
      "0.55596    10\n",
      "0.52964    10\n",
      "0.48030    10\n",
      "0.54860    10\n",
      "0.51775    10\n",
      "0.54604    10\n",
      "0.53279    10\n",
      "0.56914    10\n",
      "0.54576    10\n",
      "0.53806    10\n",
      "0.53415    10\n",
      "0.54888    10\n",
      "0.54441    10\n",
      "0.56042     9\n",
      "0.52550     9\n",
      "0.54192     9\n",
      "0.56740     9\n",
      "0.54850     9\n",
      "0.54958     9\n",
      "0.52719     9\n",
      "0.51030     9\n",
      "0.56619     9\n",
      "0.53929     9\n",
      "0.51932     9\n",
      "0.55496     9\n",
      "0.52689     9\n",
      "0.53356     9\n",
      "           ..\n",
      "0.28945     1\n",
      "0.53633     1\n",
      "0.44114     1\n",
      "0.58746     1\n",
      "0.62009     1\n",
      "0.35415     1\n",
      "0.68056     1\n",
      "0.28507     1\n",
      "0.44824     1\n",
      "0.59841     1\n",
      "0.56628     1\n",
      "0.42079     1\n",
      "0.39913     1\n",
      "0.43426     1\n",
      "0.72262     1\n",
      "0.65316     1\n",
      "0.37953     1\n",
      "0.30129     1\n",
      "0.63674     1\n",
      "0.37985     1\n",
      "0.47607     1\n",
      "0.36749     1\n",
      "0.40897     1\n",
      "0.60102     1\n",
      "0.43546     1\n",
      "0.37897     1\n",
      "0.59102     1\n",
      "0.75214     1\n",
      "0.40490     1\n",
      "0.56860     1\n",
      "Name: feature19, Length: 28466, dtype: int64 \n",
      "\n",
      "\n",
      "0.50924    11\n",
      "0.49903    11\n",
      "0.47026    11\n",
      "0.46387    11\n",
      "0.47367    11\n",
      "0.48699    11\n",
      "0.46064    11\n",
      "0.50029    11\n",
      "0.47965    10\n",
      "0.47572    10\n",
      "0.47373    10\n",
      "0.47478    10\n",
      "0.49330    10\n",
      "0.48406    10\n",
      "0.47016    10\n",
      "0.49198    10\n",
      "0.47898    10\n",
      "0.48202    10\n",
      "0.48400    10\n",
      "0.47844    10\n",
      "0.48051    10\n",
      "0.47970    10\n",
      "0.49051    10\n",
      "0.47165    10\n",
      "0.50226    10\n",
      "0.49536    10\n",
      "0.47678    10\n",
      "0.49053    10\n",
      "0.45613    10\n",
      "0.48994    10\n",
      "           ..\n",
      "0.34077     1\n",
      "0.39534     1\n",
      "0.31447     1\n",
      "0.56687     1\n",
      "0.68514     1\n",
      "0.65633     1\n",
      "0.65317     1\n",
      "0.33897     1\n",
      "0.58295     1\n",
      "0.22801     1\n",
      "0.36096     1\n",
      "0.31326     1\n",
      "0.55605     1\n",
      "0.31745     1\n",
      "0.60932     1\n",
      "0.67194     1\n",
      "0.36518     1\n",
      "0.33456     1\n",
      "0.28402     1\n",
      "0.56506     1\n",
      "0.69616     1\n",
      "0.64794     1\n",
      "0.26939     1\n",
      "0.39973     1\n",
      "0.66611     1\n",
      "0.55497     1\n",
      "0.73822     1\n",
      "0.79456     1\n",
      "0.48381     1\n",
      "0.44800     1\n",
      "Name: feature20, Length: 28716, dtype: int64 \n",
      "\n",
      "\n",
      "0.42420    11\n",
      "0.38604    11\n",
      "0.41236    10\n",
      "0.38958    10\n",
      "0.39987    10\n",
      "0.39730    10\n",
      "0.43390     9\n",
      "0.39515     9\n",
      "0.41471     9\n",
      "0.41547     9\n",
      "0.42401     9\n",
      "0.39946     9\n",
      "0.38028     9\n",
      "0.46851     9\n",
      "0.41285     9\n",
      "0.44514     9\n",
      "0.47843     8\n",
      "0.43069     8\n",
      "0.45638     8\n",
      "0.43099     8\n",
      "0.39620     8\n",
      "0.41500     8\n",
      "0.39686     8\n",
      "0.42936     8\n",
      "0.39826     8\n",
      "0.38822     8\n",
      "0.42954     8\n",
      "0.34982     8\n",
      "0.42363     8\n",
      "0.43531     8\n",
      "           ..\n",
      "0.55942     1\n",
      "0.27608     1\n",
      "0.53724     1\n",
      "0.52486     1\n",
      "0.20791     1\n",
      "0.47040     1\n",
      "0.60748     1\n",
      "0.21458     1\n",
      "0.46859     1\n",
      "0.35571     1\n",
      "0.63059     1\n",
      "0.61305     1\n",
      "0.27809     1\n",
      "0.57610     1\n",
      "0.39776     1\n",
      "0.32232     1\n",
      "0.35205     1\n",
      "0.63933     1\n",
      "0.55758     1\n",
      "0.69742     1\n",
      "0.38299     1\n",
      "0.72105     1\n",
      "0.69667     1\n",
      "0.25248     1\n",
      "0.69836     1\n",
      "0.58879     1\n",
      "0.63989     1\n",
      "0.51639     1\n",
      "0.31225     1\n",
      "0.00000     1\n",
      "Name: feature21, Length: 31223, dtype: int64 \n",
      "\n",
      "\n",
      "1    32796\n",
      "0    32247\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(data[i].value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categoric = [\"feature13\",\"feature14\",\"feature15\",\"feature16\",\"feature17\"]\n",
    "drop = [\"id\"]\n",
    "output = [\"target\"]\n",
    "numeric = [x for x in data.columns if x not in categoric and x not in drop and x not in output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImportData(data, drop):\n",
    "    data = pd.read_csv(data)\n",
    "    data = data.drop(drop, axis=1)\n",
    "    print(\"Amount of observations and features:\", data.shape)\n",
    "    print(\"Amount of duplicate data:\", data.duplicated().sum())\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Amount of observations and features after removing duplicates:\", data.shape)\n",
    "    print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of observations and features: (65043, 22)\n",
      "Amount of duplicate data: 0\n",
      "Amount of observations and features after removing duplicates: (65043, 22)\n",
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0       NaN   0.58268   0.57387   0.47334   0.43624   0.51407   0.56079   \n",
      "1   0.51490   0.57116   0.54893   0.54678   0.48280   0.50677   0.48026   \n",
      "2   0.52758   0.52880   0.59754   0.44720   0.40589   0.46379   0.60392   \n",
      "3   0.59609       NaN   0.54468   0.44602   0.45216   0.46244   0.51467   \n",
      "4   0.55105   0.43209   0.61949   0.36115   0.37597   0.44154   0.62260   \n",
      "\n",
      "   feature8  feature9  feature10   ...    feature13  feature14 feature15  \\\n",
      "0   0.48107       NaN    0.59843   ...       medium     medium    medium   \n",
      "1   0.46114   0.33667    0.59444   ...       medium     medium    medium   \n",
      "2   0.44801   0.33079    0.53333   ...       medium       high    medium   \n",
      "3   0.42857   0.54993    0.45275   ...       medium        NaN    medium   \n",
      "4   0.45039   0.44299    0.45635   ...       medium     medium    medium   \n",
      "\n",
      "  feature16 feature17 feature18 feature19  feature20  feature21  target  \n",
      "0    medium    medium   0.58190   0.52786    0.46630    0.39546       1  \n",
      "1    medium    medium   0.53465   0.54336    0.42988    0.35608       1  \n",
      "2    medium    medium   0.60216   0.58529    0.47515    0.44429       1  \n",
      "3    medium    medium   0.56061   0.43781    0.55344        NaN       0  \n",
      "4    medium    medium   0.64087   0.53343    0.56798    0.58223       1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data_raw = ImportData('numerai_training.csv', drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExtractInputOutput(data, output):\n",
    "    data_output = data[output]\n",
    "    data_input = data.drop(output, axis=1)\n",
    "    return data_input, data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_input, data_output = ExtractInputOutput(data_raw, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0       NaN   0.58268   0.57387   0.47334   0.43624   0.51407   0.56079   \n",
      "1   0.51490   0.57116   0.54893   0.54678   0.48280   0.50677   0.48026   \n",
      "2   0.52758   0.52880   0.59754   0.44720   0.40589   0.46379   0.60392   \n",
      "3   0.59609       NaN   0.54468   0.44602   0.45216   0.46244   0.51467   \n",
      "4   0.55105   0.43209   0.61949   0.36115   0.37597   0.44154   0.62260   \n",
      "\n",
      "   feature8  feature9  feature10    ...      feature12  feature13 feature14  \\\n",
      "0   0.48107       NaN    0.59843    ...        0.49728     medium    medium   \n",
      "1   0.46114   0.33667    0.59444    ...        0.55845     medium    medium   \n",
      "2   0.44801   0.33079    0.53333    ...        0.46647     medium      high   \n",
      "3   0.42857   0.54993    0.45275    ...        0.42288     medium       NaN   \n",
      "4   0.45039   0.44299    0.45635    ...        0.36837     medium    medium   \n",
      "\n",
      "  feature15 feature16 feature17 feature18  feature19  feature20  feature21  \n",
      "0    medium    medium    medium   0.58190    0.52786    0.46630    0.39546  \n",
      "1    medium    medium    medium   0.53465    0.54336    0.42988    0.35608  \n",
      "2    medium    medium    medium   0.60216    0.58529    0.47515    0.44429  \n",
      "3    medium    medium    medium   0.56061    0.43781    0.55344        NaN  \n",
      "4    medium    medium    medium   0.64087    0.53343    0.56798    0.58223  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   target\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       0\n",
      "4       1\n"
     ]
    }
   ],
   "source": [
    "print(data_input.head())\n",
    "print(data_output.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_data(x,y): \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.25,\n",
    "                                                        random_state =123)\n",
    "    print(x_train.head(), y_train.head()) #\n",
    "    print(x_test.head(), y_test.head()) #\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "34082   0.51468   0.59975   0.56179   0.49835   0.45791   0.58743   0.54548   \n",
      "14903   0.44828   0.57494   0.59232   0.53950   0.46571   0.59479   0.44565   \n",
      "45648   0.48262   0.57208   0.63338   0.42016   0.37442   0.52434   0.64892   \n",
      "46088   0.48284   0.61796   0.55094   0.52517   0.48494   0.58440   0.47477   \n",
      "31221   0.64643   0.65817   0.38047   0.66255   0.62211   0.55008   0.40235   \n",
      "\n",
      "       feature8  feature9  feature10    ...      feature12  feature13  \\\n",
      "34082   0.46705   0.27490    0.59717    ...        0.51207     medium   \n",
      "14903   0.51618   0.28507    0.61961    ...        0.53250     medium   \n",
      "45648   0.48007   0.21604    0.57225    ...        0.44972     medium   \n",
      "46088   0.51014   0.27675    0.65482    ...        0.54458     medium   \n",
      "31221   0.37903   0.45163    0.63024    ...        0.67292     medium   \n",
      "\n",
      "      feature14 feature15 feature16 feature17 feature18  feature19  feature20  \\\n",
      "34082    medium    medium    medium    medium   0.56165    0.54495    0.44845   \n",
      "14903    medium    medium    medium    medium   0.56964    0.51509    0.45628   \n",
      "45648      high      high    medium    medium   0.64006    0.61404    0.47110   \n",
      "46088    medium    medium    medium    medium   0.54856    0.48578    0.45059   \n",
      "31221    medium    medium    medium    medium   0.37823    0.45332    0.36069   \n",
      "\n",
      "       feature21  \n",
      "34082    0.38101  \n",
      "14903    0.34590  \n",
      "45648    0.41304  \n",
      "46088    0.33937  \n",
      "31221    0.30891  \n",
      "\n",
      "[5 rows x 21 columns]        target\n",
      "34082       1\n",
      "14903       1\n",
      "45648       1\n",
      "46088       1\n",
      "31221       0\n",
      "       feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "25638   0.53363   0.48150   0.59478   0.45495   0.41954   0.51953   0.54378   \n",
      "52851   0.39510   0.44955   0.62180   0.43556   0.48128   0.55677   0.32537   \n",
      "20779   0.50419   0.55502   0.55715   0.48885   0.49059   0.61056   0.47112   \n",
      "63273   0.54049   0.69281   0.47525   0.62721   0.53430   0.51390   0.46774   \n",
      "14480   0.36553   0.56546   0.67885   0.42365   0.37462       NaN   0.51064   \n",
      "\n",
      "       feature8  feature9  feature10    ...      feature12  feature13  \\\n",
      "25638   0.45172   0.41293    0.48518    ...        0.43312     medium   \n",
      "52851   0.62704   0.41240    0.64452    ...        0.45467     medium   \n",
      "20779   0.49261   0.33031    0.60379    ...        0.50602     medium   \n",
      "63273   0.44553   0.30249    0.68950    ...        0.65403     medium   \n",
      "14480   0.61111   0.21021    0.64746    ...        0.42417        low   \n",
      "\n",
      "      feature14 feature15 feature16 feature17 feature18  feature19  feature20  \\\n",
      "25638    medium    medium    medium    medium   0.59492    0.51511    0.51849   \n",
      "52851       NaN    medium    medium    medium   0.61533    0.36747    0.60671   \n",
      "20779    medium    medium    medium    medium   0.55358    0.50558    0.48759   \n",
      "63273    medium    medium    medium    medium   0.46780    0.51463    0.35044   \n",
      "14480      high    medium       low    medium   0.67956    0.45347    0.54401   \n",
      "\n",
      "       feature21  \n",
      "25638    0.50355  \n",
      "52851    0.46313  \n",
      "20779    0.41198  \n",
      "63273    0.24036  \n",
      "14480    0.39614  \n",
      "\n",
      "[5 rows x 21 columns]        target\n",
      "25638       0\n",
      "52851       1\n",
      "20779       1\n",
      "63273       1\n",
      "14480       0\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_data(data_input, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     1542\n",
       "feature2     2011\n",
       "feature3      152\n",
       "feature4      754\n",
       "feature5     1222\n",
       "feature6     2148\n",
       "feature7      928\n",
       "feature8     2175\n",
       "feature9     2218\n",
       "feature10     612\n",
       "feature11    1039\n",
       "feature12    1572\n",
       "feature13     189\n",
       "feature14    1549\n",
       "feature15     771\n",
       "feature16    1083\n",
       "feature17     247\n",
       "feature18    1004\n",
       "feature19    1431\n",
       "feature20     225\n",
       "feature21    1701\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numerical_col.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(x_train.columns, 'input_col.pkl')\n",
    "joblib.dump(categoric, 'categorical_col.pkl')\n",
    "joblib.dump(numeric,'numerical_col.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CategoricalDummies(data):\n",
    "    data = data.fillna(\"KOSONG\")\n",
    "    dummy_variables = pd.DataFrame()\n",
    "    label_encoder = pd.Series([])\n",
    "    label_binarizer = pd.Series([])\n",
    "    \n",
    "    for i in list(data):\n",
    "        label_en = LabelEncoder()\n",
    "        label_bin = LabelBinarizer()\n",
    "        \n",
    "        encoded = label_en.fit_transform(data[i])\n",
    "        binary = label_bin.fit_transform(encoded)\n",
    "        \n",
    "        if binary.shape[1] == 1:\n",
    "            dummy = pd.DataFrame(binary, columns = [i], index = data.index)\n",
    "        else:\n",
    "            dummy = pd.DataFrame(binary, columns = [\"{}_{}\".format(a,b) for b in sorted(data[i].unique())\n",
    "                                                   for a in [i]],\n",
    "                                index = data.index)\n",
    "        \n",
    "        dummy_variables = pd.concat([dummy_variables, dummy], axis = 1)\n",
    "        label_encoder[i] = label_en\n",
    "        label_binarizer[i] = label_bin\n",
    "        \n",
    "    return dummy_variables, label_encoder, label_binarizer, dummy_variables.columns    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_dummy, label_encoder, label_binarizer, dummy_columns = CategoricalDummies(x_train[categoric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature13_KOSONG    0\n",
       "feature13_high      0\n",
       "feature13_low       0\n",
       "feature13_medium    0\n",
       "feature14_KOSONG    0\n",
       "feature14_high      0\n",
       "feature14_low       0\n",
       "feature14_medium    0\n",
       "feature15_KOSONG    0\n",
       "feature15_high      0\n",
       "feature15_low       0\n",
       "feature15_medium    0\n",
       "feature16_KOSONG    0\n",
       "feature16_high      0\n",
       "feature16_low       0\n",
       "feature16_medium    0\n",
       "feature17_KOSONG    0\n",
       "feature17_high      0\n",
       "feature17_low       0\n",
       "feature17_medium    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_dummy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_binarizer.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dummy_columns, 'dummy_col.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "joblib.dump(label_binarizer, 'label_binarizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitImputNum(data, numeric_column, missing_values, method):\n",
    "    imput = Imputer(missing_values=missing_values, strategy = method)\n",
    "    imput.fit(data[numeric_column])\n",
    "    return data[numeric_column], imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_numeric, imput = fitImputNum(x_train, numeric, 'NaN','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformImput(data, imputer):\n",
    "    data_numeric = pd.DataFrame(imputer.transform(data))\n",
    "    data_numeric.columns = data.columns\n",
    "    data_numeric.index = data.index\n",
    "    print(data_numeric.isnull().sum())\n",
    "    print(data_numeric.head())\n",
    "    return data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1     0\n",
      "feature2     0\n",
      "feature3     0\n",
      "feature4     0\n",
      "feature5     0\n",
      "feature6     0\n",
      "feature7     0\n",
      "feature8     0\n",
      "feature9     0\n",
      "feature10    0\n",
      "feature11    0\n",
      "feature12    0\n",
      "feature18    0\n",
      "feature19    0\n",
      "feature20    0\n",
      "feature21    0\n",
      "dtype: int64\n",
      "       feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "34082   0.51468   0.59975   0.56179   0.49835   0.45791   0.58743   0.54548   \n",
      "14903   0.44828   0.57494   0.59232   0.53950   0.46571   0.59479   0.44565   \n",
      "45648   0.48262   0.57208   0.63338   0.42016   0.37442   0.52434   0.64892   \n",
      "46088   0.48284   0.61796   0.55094   0.52517   0.48494   0.58440   0.47477   \n",
      "31221   0.64643   0.65817   0.38047   0.66255   0.62211   0.55008   0.40235   \n",
      "\n",
      "       feature8  feature9  feature10  feature11  feature12  feature18  \\\n",
      "34082   0.46705   0.27490    0.59717    0.45014    0.51207    0.56165   \n",
      "14903   0.51618   0.28507    0.61961    0.44620    0.53250    0.56964   \n",
      "45648   0.48007   0.21604    0.57225    0.37488    0.44972    0.64006   \n",
      "46088   0.51014   0.27675    0.65482    0.46520    0.54458    0.54856   \n",
      "31221   0.37903   0.45163    0.63024    0.62779    0.67292    0.37823   \n",
      "\n",
      "       feature19  feature20  feature21  \n",
      "34082    0.54495    0.44845    0.38101  \n",
      "14903    0.51509    0.45628    0.34590  \n",
      "45648    0.61404    0.47110    0.41304  \n",
      "46088    0.48578    0.45059    0.33937  \n",
      "31221    0.45332    0.36069    0.30891  \n"
     ]
    }
   ],
   "source": [
    "x_train_imput_num = transformImput(x_train_numeric, imput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imputer.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(numeric, 'numerical_col.pkl')\n",
    "joblib.dump(imput, 'imputer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Categoric & Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fitStandardize(data):\n",
    "    standard = StandardScaler()\n",
    "    standard.fit(data)\n",
    "    return standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformStandardize(data, standard):\n",
    "    data_standard = pd.DataFrame(standard.transform(data))\n",
    "    data_standard.columns = data.columns\n",
    "    data_standard.index = data.index\n",
    "    print(data_standard.head())\n",
    "    return data_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "34082  0.161881  0.687222 -0.319286  0.363399  0.320916  0.869563  0.122300   \n",
      "14903 -0.586140  0.444985 -0.008227  0.794275  0.410489  0.942978 -0.904334   \n",
      "45648 -0.199286  0.417061  0.410120 -0.455316 -0.637861  0.240246  1.186058   \n",
      "46088 -0.196808  0.865019 -0.429833  0.644227  0.631321  0.839339 -0.604869   \n",
      "31221  1.646095  1.257617 -2.166694  2.082711  2.206545  0.497000 -1.349624   \n",
      "\n",
      "       feature8  feature9  feature10  feature11  feature12  feature18  \\\n",
      "34082 -0.207979 -0.729533   0.324986   0.355177   0.359453  -0.337585   \n",
      "14903  0.365307 -0.627073   0.559971   0.314236   0.560423  -0.254851   \n",
      "45648 -0.056052 -1.322533   0.064032  -0.426853  -0.253882   0.474322   \n",
      "46088  0.294828 -0.710894   0.928679   0.511666   0.679254  -0.473127   \n",
      "31221 -1.235064  1.050979   0.671285   2.201145   1.941732  -2.236833   \n",
      "\n",
      "       feature19  feature20  feature21  \n",
      "34082   0.224693  -0.501421  -0.502523  \n",
      "14903  -0.115904  -0.414127  -0.844620  \n",
      "45648   1.012767  -0.248904  -0.190436  \n",
      "46088  -0.450228  -0.477563  -0.908245  \n",
      "31221  -0.820483  -1.479825  -1.205034  \n"
     ]
    }
   ],
   "source": [
    "standard = fitStandardize(x_train_imput_num)\n",
    "x_train_standardize = transformStandardize(x_train_imput_num, standard=standard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizer.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(standard, 'normalizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_clean = pd.concat([data_train_dummy, x_train_standardize], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_clean.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature13_KOSONG</th>\n",
       "      <th>feature13_high</th>\n",
       "      <th>feature13_low</th>\n",
       "      <th>feature13_medium</th>\n",
       "      <th>feature14_KOSONG</th>\n",
       "      <th>feature14_high</th>\n",
       "      <th>feature14_low</th>\n",
       "      <th>feature14_medium</th>\n",
       "      <th>feature15_KOSONG</th>\n",
       "      <th>feature15_high</th>\n",
       "      <th>...</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34082</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>-0.207979</td>\n",
       "      <td>-0.729533</td>\n",
       "      <td>0.324986</td>\n",
       "      <td>0.355177</td>\n",
       "      <td>0.359453</td>\n",
       "      <td>-0.337585</td>\n",
       "      <td>0.224693</td>\n",
       "      <td>-0.501421</td>\n",
       "      <td>-0.502523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.904334</td>\n",
       "      <td>0.365307</td>\n",
       "      <td>-0.627073</td>\n",
       "      <td>0.559971</td>\n",
       "      <td>0.314236</td>\n",
       "      <td>0.560423</td>\n",
       "      <td>-0.254851</td>\n",
       "      <td>-0.115904</td>\n",
       "      <td>-0.414127</td>\n",
       "      <td>-0.844620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45648</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.186058</td>\n",
       "      <td>-0.056052</td>\n",
       "      <td>-1.322533</td>\n",
       "      <td>0.064032</td>\n",
       "      <td>-0.426853</td>\n",
       "      <td>-0.253882</td>\n",
       "      <td>0.474322</td>\n",
       "      <td>1.012767</td>\n",
       "      <td>-0.248904</td>\n",
       "      <td>-0.190436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46088</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604869</td>\n",
       "      <td>0.294828</td>\n",
       "      <td>-0.710894</td>\n",
       "      <td>0.928679</td>\n",
       "      <td>0.511666</td>\n",
       "      <td>0.679254</td>\n",
       "      <td>-0.473127</td>\n",
       "      <td>-0.450228</td>\n",
       "      <td>-0.477563</td>\n",
       "      <td>-0.908245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.349624</td>\n",
       "      <td>-1.235064</td>\n",
       "      <td>1.050979</td>\n",
       "      <td>0.671285</td>\n",
       "      <td>2.201145</td>\n",
       "      <td>1.941732</td>\n",
       "      <td>-2.236833</td>\n",
       "      <td>-0.820483</td>\n",
       "      <td>-1.479825</td>\n",
       "      <td>-1.205034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature13_KOSONG  feature13_high  feature13_low  feature13_medium  \\\n",
       "34082                 0               0              0                 1   \n",
       "14903                 0               0              0                 1   \n",
       "45648                 0               0              0                 1   \n",
       "46088                 0               0              0                 1   \n",
       "31221                 0               0              0                 1   \n",
       "\n",
       "       feature14_KOSONG  feature14_high  feature14_low  feature14_medium  \\\n",
       "34082                 0               0              0                 1   \n",
       "14903                 0               0              0                 1   \n",
       "45648                 0               1              0                 0   \n",
       "46088                 0               0              0                 1   \n",
       "31221                 0               0              0                 1   \n",
       "\n",
       "       feature15_KOSONG  feature15_high    ...      feature7  feature8  \\\n",
       "34082                 0               0    ...      0.122300 -0.207979   \n",
       "14903                 0               0    ...     -0.904334  0.365307   \n",
       "45648                 0               1    ...      1.186058 -0.056052   \n",
       "46088                 0               0    ...     -0.604869  0.294828   \n",
       "31221                 0               0    ...     -1.349624 -1.235064   \n",
       "\n",
       "       feature9  feature10  feature11  feature12  feature18  feature19  \\\n",
       "34082 -0.729533   0.324986   0.355177   0.359453  -0.337585   0.224693   \n",
       "14903 -0.627073   0.559971   0.314236   0.560423  -0.254851  -0.115904   \n",
       "45648 -1.322533   0.064032  -0.426853  -0.253882   0.474322   1.012767   \n",
       "46088 -0.710894   0.928679   0.511666   0.679254  -0.473127  -0.450228   \n",
       "31221  1.050979   0.671285   2.201145   1.941732  -2.236833  -0.820483   \n",
       "\n",
       "       feature20  feature21  \n",
       "34082  -0.501421  -0.502523  \n",
       "14903  -0.414127  -0.844620  \n",
       "45648  -0.248904  -0.190436  \n",
       "46088  -0.477563  -0.908245  \n",
       "31221  -1.479825  -1.205034  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logreg_fit(x_train, y_train):\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    hyperparam = {'C': [1000, 333.33, 100, 33.33, 10, 3.33, 10, 3.33, 1, 0.33, 0.1, 0.033, 0.01, 0.0033, \n",
    "                        0.001, 0.00033, 0.0001]}\n",
    "\n",
    "    random_logreg = RandomizedSearchCV(logreg, param_distributions = hyperparam, cv = 5,\n",
    "                                    n_iter = 5, n_jobs=-1, random_state = 123)\n",
    "    \n",
    "    random_logreg.fit(x_train, y_train)\n",
    "    \n",
    "    print (\"Best Accuracy\", random_logreg.score(x_train, y_train))\n",
    "    print (\"Best Param\", random_logreg.best_params_)\n",
    "    \n",
    "    return random_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48782, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48782, 36)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy 0.521052847362\n",
      "Best Param {'C': 3.33}\n"
     ]
    }
   ],
   "source": [
    "best_logreg = logreg_fit(x_train_clean, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gibranerlangga/anaconda/envs/ENVNAME/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.33, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=best_logreg.best_params_.get('C'))\n",
    "logreg.fit(x_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gibranerlangga/anaconda/envs/ENVNAME/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52105284736173174"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg0 = LogisticRegression(C=10**8)\n",
    "logreg0.fit(x_train_clean, y_train)\n",
    "logreg0.score(x_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/gibranerlangga/anaconda/envs/ENVNAME/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import Sequential \n",
    "from keras.models import Sequential\n",
    "# import Dense \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "\n",
    "model0.add(Dense(1,input_dim = 36, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48782/48782 [==============================] - 2s 38us/step - loss: 0.7025 - acc: 0.5020\n",
      "Epoch 2/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6948 - acc: 0.5099\n",
      "Epoch 3/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6943 - acc: 0.5080\n",
      "Epoch 4/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6940 - acc: 0.5102\n",
      "Epoch 5/20\n",
      "48782/48782 [==============================] - 2s 33us/step - loss: 0.6937 - acc: 0.5122\n",
      "Epoch 6/20\n",
      "48782/48782 [==============================] - 2s 33us/step - loss: 0.6935 - acc: 0.5109\n",
      "Epoch 7/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6933 - acc: 0.5128\n",
      "Epoch 8/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6931 - acc: 0.5129\n",
      "Epoch 9/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6930 - acc: 0.5145\n",
      "Epoch 10/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6929 - acc: 0.5139\n",
      "Epoch 11/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 12/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6927 - acc: 0.5150\n",
      "Epoch 13/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6928 - acc: 0.5158\n",
      "Epoch 14/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6926 - acc: 0.5159\n",
      "Epoch 15/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6927 - acc: 0.5160\n",
      "Epoch 16/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6927 - acc: 0.5177\n",
      "Epoch 17/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6927 - acc: 0.5166\n",
      "Epoch 18/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6925 - acc: 0.5171\n",
      "Epoch 19/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6925 - acc: 0.5182\n",
      "Epoch 20/20\n",
      "48782/48782 [==============================] - 2s 34us/step - loss: 0.6926 - acc: 0.5166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1213af9e8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.fit(x_train_clean.values, y_train.values, epochs=20, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48782/48782 [==============================] - 1s 18us/step\n",
      "\n",
      "loss: 0.69\n",
      "acc: 51.27%\n"
     ]
    }
   ],
   "source": [
    "scores = model0.evaluate(x_train_clean.values, y_train.values)\n",
    "print()\n",
    "print(\"%s: %.2f\" % (model0.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model0.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 37        \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.save('model0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "#add input layer\n",
    "model1.add(Dense(18, input_dim = 36, activation = 'relu'))\n",
    "\n",
    "#add hidden layer\n",
    "model1.add(Dense(12, activation = 'relu'))\n",
    "\n",
    "#add output layer\n",
    "model1.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48782/48782 [==============================] - 3s 59us/step - loss: 0.6966 - acc: 0.5028\n",
      "Epoch 2/20\n",
      "48782/48782 [==============================] - 3s 55us/step - loss: 0.6936 - acc: 0.5077\n",
      "Epoch 3/20\n",
      "48782/48782 [==============================] - 2s 45us/step - loss: 0.6932 - acc: 0.5077\n",
      "Epoch 4/20\n",
      "48782/48782 [==============================] - 3s 55us/step - loss: 0.6930 - acc: 0.5099\n",
      "Epoch 5/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6928 - acc: 0.5108\n",
      "Epoch 6/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6926 - acc: 0.5110\n",
      "Epoch 7/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6926 - acc: 0.5115\n",
      "Epoch 8/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6924 - acc: 0.5140\n",
      "Epoch 9/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6924 - acc: 0.5134\n",
      "Epoch 10/20\n",
      "48782/48782 [==============================] - 2s 41us/step - loss: 0.6923 - acc: 0.5138\n",
      "Epoch 11/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6923 - acc: 0.5161\n",
      "Epoch 12/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6923 - acc: 0.5128\n",
      "Epoch 13/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6923 - acc: 0.5163\n",
      "Epoch 14/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6922 - acc: 0.5166\n",
      "Epoch 15/20\n",
      "48782/48782 [==============================] - 2s 40us/step - loss: 0.6921 - acc: 0.5162\n",
      "Epoch 16/20\n",
      "48782/48782 [==============================] - 2s 41us/step - loss: 0.6921 - acc: 0.5180\n",
      "Epoch 17/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6921 - acc: 0.5163\n",
      "Epoch 18/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6920 - acc: 0.5191\n",
      "Epoch 19/20\n",
      "48782/48782 [==============================] - 2s 39us/step - loss: 0.6920 - acc: 0.5189\n",
      "Epoch 20/20\n",
      "48782/48782 [==============================] - 2s 40us/step - loss: 0.6920 - acc: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124536d30>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train_clean.values, y_train.values, epochs=20, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 18)                666       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 907\n",
      "Trainable params: 907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48782/48782 [==============================] - 1s 29us/step\n",
      "acc: 52.03%\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(x_train_clean.values, y_train.values)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with 2 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "#add input layer\n",
    "model2.add(Dense(18, input_dim = 36, activation = 'relu'))\n",
    "\n",
    "#add hidden layer 1\n",
    "model2.add(Dense(12, activation = 'relu'))\n",
    "\n",
    "#add hidden layer 2\n",
    "model2.add(Dense(6, activation = 'relu'))\n",
    "\n",
    "#add output layer\n",
    "model2.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48782/48782 [==============================] - 3s 63us/step - loss: 0.6940 - acc: 0.5091\n",
      "Epoch 2/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6927 - acc: 0.5125\n",
      "Epoch 3/20\n",
      "48782/48782 [==============================] - 3s 58us/step - loss: 0.6924 - acc: 0.5173\n",
      "Epoch 4/20\n",
      "48782/48782 [==============================] - 3s 57us/step - loss: 0.6923 - acc: 0.5187\n",
      "Epoch 5/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6922 - acc: 0.5174\n",
      "Epoch 6/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6921 - acc: 0.5185\n",
      "Epoch 7/20\n",
      "48782/48782 [==============================] - 3s 57us/step - loss: 0.6920 - acc: 0.5187\n",
      "Epoch 8/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6920 - acc: 0.5207\n",
      "Epoch 9/20\n",
      "48782/48782 [==============================] - 3s 58us/step - loss: 0.6918 - acc: 0.5219\n",
      "Epoch 10/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6918 - acc: 0.5221\n",
      "Epoch 11/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6917 - acc: 0.5217\n",
      "Epoch 12/20\n",
      "48782/48782 [==============================] - 3s 58us/step - loss: 0.6917 - acc: 0.5227\n",
      "Epoch 13/20\n",
      "48782/48782 [==============================] - 3s 59us/step - loss: 0.6916 - acc: 0.5220\n",
      "Epoch 14/20\n",
      "48782/48782 [==============================] - 3s 60us/step - loss: 0.6916 - acc: 0.5238\n",
      "Epoch 15/20\n",
      "48782/48782 [==============================] - 3s 63us/step - loss: 0.6915 - acc: 0.5240\n",
      "Epoch 16/20\n",
      "48782/48782 [==============================] - 3s 61us/step - loss: 0.6915 - acc: 0.5242\n",
      "Epoch 17/20\n",
      "48782/48782 [==============================] - 3s 59us/step - loss: 0.6915 - acc: 0.5244\n",
      "Epoch 18/20\n",
      "48782/48782 [==============================] - 3s 61us/step - loss: 0.6914 - acc: 0.5237\n",
      "Epoch 19/20\n",
      "48782/48782 [==============================] - 3s 64us/step - loss: 0.6914 - acc: 0.5249\n",
      "Epoch 20/20\n",
      "48782/48782 [==============================] - 3s 61us/step - loss: 0.6913 - acc: 0.5255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1232d0668>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train_clean.values, y_train.values, epochs = 20, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48782/48782 [==============================] - 2s 32us/step\n",
      "acc: 52.49%\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(x_train_clean.values, y_train.values)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with 3 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(18, input_dim = 36, activation = 'relu'))\n",
    "\n",
    "model3.add(Dense(12, activation='relu'))\n",
    "model3.add(Dense(6, activation='relu'))\n",
    "model3.add(Dense(3, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48782/48782 [==============================] - 3s 67us/step - loss: 0.6941 - acc: 0.4975\n",
      "Epoch 2/20\n",
      "48782/48782 [==============================] - 3s 57us/step - loss: 0.6932 - acc: 0.5058\n",
      "Epoch 3/20\n",
      "48782/48782 [==============================] - 3s 58us/step - loss: 0.6931 - acc: 0.5065\n",
      "Epoch 4/20\n",
      "48782/48782 [==============================] - 3s 62us/step - loss: 0.6931 - acc: 0.5062\n",
      "Epoch 5/20\n",
      "48782/48782 [==============================] - 3s 62us/step - loss: 0.6930 - acc: 0.5065\n",
      "Epoch 6/20\n",
      "48782/48782 [==============================] - 3s 63us/step - loss: 0.6930 - acc: 0.5066\n",
      "Epoch 7/20\n",
      "48782/48782 [==============================] - 3s 61us/step - loss: 0.6929 - acc: 0.5067\n",
      "Epoch 8/20\n",
      "48782/48782 [==============================] - 3s 61us/step - loss: 0.6928 - acc: 0.5075\n",
      "Epoch 9/20\n",
      "48782/48782 [==============================] - 3s 68us/step - loss: 0.6927 - acc: 0.5105\n",
      "Epoch 10/20\n",
      "48782/48782 [==============================] - 3s 66us/step - loss: 0.6927 - acc: 0.5106\n",
      "Epoch 11/20\n",
      "48782/48782 [==============================] - 3s 68us/step - loss: 0.6926 - acc: 0.5124\n",
      "Epoch 12/20\n",
      "48782/48782 [==============================] - 5s 99us/step - loss: 0.6926 - acc: 0.5118\n",
      "Epoch 13/20\n",
      "48782/48782 [==============================] - 4s 76us/step - loss: 0.6925 - acc: 0.5124\n",
      "Epoch 14/20\n",
      "48782/48782 [==============================] - 4s 74us/step - loss: 0.6925 - acc: 0.5112\n",
      "Epoch 15/20\n",
      "48782/48782 [==============================] - 4s 77us/step - loss: 0.6925 - acc: 0.5125\n",
      "Epoch 16/20\n",
      "48782/48782 [==============================] - 2s 48us/step - loss: 0.6925 - acc: 0.5137\n",
      "Epoch 17/20\n",
      "48782/48782 [==============================] - 3s 57us/step - loss: 0.6925 - acc: 0.5140\n",
      "Epoch 18/20\n",
      "48782/48782 [==============================] - 3s 56us/step - loss: 0.6924 - acc: 0.5145\n",
      "Epoch 19/20\n",
      "48782/48782 [==============================] - 3s 58us/step - loss: 0.6924 - acc: 0.5143\n",
      "Epoch 20/20\n",
      "48782/48782 [==============================] - 3s 62us/step - loss: 0.6924 - acc: 0.5153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12285f550>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train_clean.values, y_train.values, epochs=20, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 18)                666       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 997\n",
      "Trainable params: 997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48782/48782 [==============================] - 2s 38us/step\n",
      "acc: 51.66%\n"
     ]
    }
   ],
   "source": [
    "scores = model3.evaluate(x_train_clean.values, y_train.values)\n",
    "print(\"%s: %.2f%%\" % (model3.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.save('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical\n",
    "def testCategoricalDummies(data, categorical_columns, label_encoder, label_binarizer,dummy_columns):\n",
    "    data = data[categorical_columns].fillna(\"KOSONG\")\n",
    "    dummy_variables = pd.DataFrame([])\n",
    "    \n",
    "    for i in categorical_columns:\n",
    "        label_en = label_encoder[i]\n",
    "        label_bin = label_binarizer[i]\n",
    "        \n",
    "        encoded = label_en.transform(data[i])\n",
    "        binary = label_bin.transform(encoded)\n",
    "        \n",
    "        if binary.shape[1] == 1:\n",
    "            dummy = pd.DataFrame(binary, index = data.index)\n",
    "        else:\n",
    "            dummy = pd.DataFrame(binary, index = data.index)\n",
    "        \n",
    "        dummy_variables = pd.concat([dummy_variables, dummy], axis = 1)\n",
    "    dummy_variables.columns = dummy_columns\n",
    "    return dummy_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validData(data, numerical_columns, categorical_columns, imputer, \n",
    "              label_encoder, label_binarizer, dummy_columns, standardizer):\n",
    "    # preprocess numerical data using transformNumerical()\n",
    "    data_numeric_imput = transformImput(data[numerical_columns], imputer=imputer)\n",
    "    # preprocess categorical data using transformCategorical()\n",
    "    data_dummy = testCategoricalDummies(data, categorical_columns, label_encoder, label_binarizer, dummy_columns)\n",
    "    data_standard = transformStandardize(data_numeric_imput, standardizer)\n",
    "    data_valid = pd.concat([data_dummy, data_standard], axis=1)\n",
    "    return data_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary object\n",
    "# object = joblib.load(\"filename.pkl\")\n",
    "numerical_columns = joblib.load('numerical_col.pkl')\n",
    "categorical_columns = joblib.load('categorical_col.pkl')\n",
    "dummy_columns = joblib.load('dummy_col.pkl')\n",
    "\n",
    "imputer = joblib.load('imputer.pkl')\n",
    "label_binarizer = joblib.load('label_binarizer.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "standardizer = joblib.load('normalizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1     0\n",
      "feature2     0\n",
      "feature3     0\n",
      "feature4     0\n",
      "feature5     0\n",
      "feature6     0\n",
      "feature7     0\n",
      "feature8     0\n",
      "feature9     0\n",
      "feature10    0\n",
      "feature11    0\n",
      "feature12    0\n",
      "feature18    0\n",
      "feature19    0\n",
      "feature20    0\n",
      "feature21    0\n",
      "dtype: int64\n",
      "       feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "25638   0.53363   0.48150   0.59478   0.45495   0.41954   0.51953   0.54378   \n",
      "52851   0.39510   0.44955   0.62180   0.43556   0.48128   0.55677   0.32537   \n",
      "20779   0.50419   0.55502   0.55715   0.48885   0.49059   0.61056   0.47112   \n",
      "63273   0.54049   0.69281   0.47525   0.62721   0.53430   0.51390   0.46774   \n",
      "14480   0.36553   0.56546   0.67885   0.42365   0.37462   0.50200   0.51064   \n",
      "\n",
      "       feature8  feature9  feature10  feature11  feature12  feature18  \\\n",
      "25638   0.45172   0.41293    0.48518    0.40763    0.43312    0.59492   \n",
      "52851   0.62704   0.41240    0.64452    0.39716    0.45467    0.61533   \n",
      "20779   0.49261   0.33031    0.60379    0.45821    0.50602    0.55358   \n",
      "63273   0.44553   0.30249    0.68950    0.54845    0.65403    0.46780   \n",
      "14480   0.61111   0.21021    0.64746    0.33321    0.42417    0.67956   \n",
      "\n",
      "       feature19  feature20  feature21  \n",
      "25638    0.51511    0.51849    0.50355  \n",
      "52851    0.36747    0.60671    0.46313  \n",
      "20779    0.50558    0.48759    0.41198  \n",
      "63273    0.51463    0.35044    0.24036  \n",
      "14480    0.45347    0.54401    0.39614  \n",
      "       feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "25638  0.375360 -0.467334  0.016838 -0.091035 -0.119715  0.192266  0.104817   \n",
      "52851 -1.185232 -0.779284  0.292135 -0.294065  0.589291  0.563732 -2.141272   \n",
      "20779  0.043708  0.250492 -0.366562  0.263926  0.696204  1.100282 -0.642405   \n",
      "63273  0.452641  1.595831 -1.201013  1.712672  1.198158  0.136108 -0.677165   \n",
      "14480 -1.518349  0.352425  0.873398 -0.418772 -0.635564  0.017406 -0.235989   \n",
      "\n",
      "       feature8  feature9  feature10  feature11  feature12  feature18  \\\n",
      "25638 -0.386862  0.661086  -0.847736  -0.086547  -0.417176   0.006914   \n",
      "52851  1.658907  0.655746   0.820820  -0.195341  -0.205189   0.218252   \n",
      "20779  0.090274 -0.171291   0.394309   0.439032   0.299940  -0.421147   \n",
      "63273 -0.459091 -0.451570   1.291836   1.376720   1.755911  -1.309368   \n",
      "14480  1.473024 -1.381269   0.851607  -0.859848  -0.505217   0.883331   \n",
      "\n",
      "       feature19  feature20  feature21  \n",
      "25638  -0.115676   0.279430   0.691455  \n",
      "52851  -1.799730   1.262963   0.297620  \n",
      "20779  -0.224380  -0.065063  -0.200764  \n",
      "63273  -0.121151  -1.594099  -1.872957  \n",
      "14480  -0.818772   0.563943  -0.355102  \n"
     ]
    }
   ],
   "source": [
    "# preprocess test data\n",
    "x_test_clean = validData(x_test, numerical_columns, categorical_columns, imputer, label_encoder, label_binarizer, dummy_columns, standardizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16261, 36)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from keras.models import load_model\n",
    "model0 = load_model('model0.h5')\n",
    "model1 = load_model('model1.h5')\n",
    "model2 = load_model('model2.h5')\n",
    "model3 = load_model('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg acc: 51.08%\n",
      "best logreg acc: 51.09%\n",
      "16261/16261 [==============================] - 1s 43us/step\n",
      " model 0 acc: 51.38%\n",
      "16261/16261 [==============================] - 1s 42us/step\n",
      " model 1 acc: 50.96%\n",
      "16261/16261 [==============================] - 1s 44us/step\n",
      " model 2 acc: 51.84%\n",
      "16261/16261 [==============================] - 1s 38us/step\n",
      " model 3 acc: 50.85%\n"
     ]
    }
   ],
   "source": [
    "# evaluate all model\n",
    "print(\"logreg acc: %.2f%%\" % (logreg0.score(x_test_clean,y_test)*100))\n",
    "print(\"best logreg acc: %.2f%%\" % (logreg.score(x_test_clean,y_test)*100))\n",
    "print(\" model 0 %s: %.2f%%\" % (model0.metrics_names[1], model0.evaluate(x_test_clean.values, y_test.values)[1]*100))\n",
    "print(\" model 1 %s: %.2f%%\" % (model1.metrics_names[1], model1.evaluate(x_test_clean.values, y_test.values)[1]*100))\n",
    "print(\" model 2 %s: %.2f%%\" % (model2.metrics_names[1], model2.evaluate(x_test_clean.values, y_test.values)[1]*100))\n",
    "print(\" model 3 %s: %.2f%%\" % (model3.metrics_names[1], model3.evaluate(x_test_clean.values, y_test.values)[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENVNAME]",
   "language": "python",
   "name": "conda-env-ENVNAME-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
